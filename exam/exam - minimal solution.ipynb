{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam: a straightforward, minimal solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import animation as ani, pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = ''\n",
    "# reading the training set\n",
    "data = pd.read_csv(data_file_path+'train_V2.csv')\n",
    "# reading the scoring set\n",
    "score = pd.read_csv(data_file_path+'score.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data sets are like real life data: messy, with mistakes, and unclarities about the exact meaning of features. The golden rule is: whenever you get into trouble, make assumptions until something starts to make sense. Therefore, we also don't give you too much input about the features - you should show that you can figure things out by yourself. \n",
    "        \n",
    "I'm going to give one extremely simplified example solution, just to show you what you could do. It is perfectly fine to stay close to this solution, although some technical improvements should hopefully be obvious after having taken the course. \n",
    "\n",
    "My approach is going to be the following: I'm going to assume that I want to predict the profit, that I want to predict who might have a damage incident (so I will make that binary), and for how much that would then be (i.e. the expected damage per incident, for a given client profile). This is obviously just one possible approach, but it might be ok under some assumptions - up to you to be aware of what they are! Again, refinements are certainly possible, and a host of interesting choices can be made as an analist here!\n",
    "\n",
    "### Preparation of data\n",
    "\n",
    "You should first focus on some data steps\n",
    "- coding categorical features we've seen in the course, so I won't do too much here\n",
    "- real feature engineering: perhaps you can take log transforms to get meaningful scales, or dividing things by number of nights to get more meaningful features,...\n",
    "- rescaling features\n",
    "- handling of data errors\n",
    "\n",
    "Ideally these things are inspired by a nice exploratory analysis, but hey: this is a *minimal* solution!\n",
    "\n",
    "Finally, a very important consideration is that everything you do has to be redone for the scoring set, exactly as it was done for the training set! To avoid a mess with mean imputations and categorization etc, I will just stitch the two together, and do the changes - this is allowed, as long as you don't use the outcome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 53)\n",
      "   income_am  profit_last_am  profit_am  damage_am  damage_inc  crd_lim_rec  \\\n",
      "0      227.0             0.0     3201.0      888.0         6.0      15000.0   \n",
      "1      268.0            16.0     1682.0        0.0         0.0        750.0   \n",
      "2      283.0            23.0     1673.0        0.0         0.0        750.0   \n",
      "3      227.0             0.0     1685.0        0.0         0.0          0.0   \n",
      "4     4091.0          1028.0     3425.0      785.0         2.0      14000.0   \n",
      "\n",
      "   credit_use_ic  gluten_ic  lactose_ic  insurance_ic  ...  score2_neg  \\\n",
      "0            0.0        0.0         0.0           0.0  ...         NaN   \n",
      "1            0.0        0.0         0.0           1.0  ...         NaN   \n",
      "2            0.0        0.0         0.0           1.0  ...    0.099529   \n",
      "3            0.0        0.0         0.0           0.0  ...         NaN   \n",
      "4            0.0        0.0         1.0           0.0  ...         NaN   \n",
      "\n",
      "   score3_pos  score3_neg  score4_pos  score4_neg  score5_pos  score5_neg  \\\n",
      "0         NaN         NaN    0.838147    0.082288         NaN         NaN   \n",
      "1         NaN         NaN         NaN         NaN         NaN    7.955259   \n",
      "2         NaN         NaN         NaN         NaN    0.101955    1.743020   \n",
      "3         NaN    0.889793         NaN         NaN         NaN         NaN   \n",
      "4    0.330503    0.766294    0.490486    0.542445         NaN         NaN   \n",
      "\n",
      "   outcome_profit  outcome_damage_inc  outcome_damage_amount  \n",
      "0         1791.66                   0                   0.00  \n",
      "1         1672.78                   1                 829.66  \n",
      "2         1001.40                   0                   0.00  \n",
      "3         1785.59                   0                   0.00  \n",
      "4         3140.74                   0                   0.00  \n",
      "\n",
      "[5 rows x 53 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income_am</th>\n",
       "      <th>profit_last_am</th>\n",
       "      <th>profit_am</th>\n",
       "      <th>damage_am</th>\n",
       "      <th>damage_inc</th>\n",
       "      <th>crd_lim_rec</th>\n",
       "      <th>credit_use_ic</th>\n",
       "      <th>gluten_ic</th>\n",
       "      <th>lactose_ic</th>\n",
       "      <th>insurance_ic</th>\n",
       "      <th>spa_ic</th>\n",
       "      <th>empl_ic</th>\n",
       "      <th>cab_requests</th>\n",
       "      <th>bar_no</th>\n",
       "      <th>sport_ic</th>\n",
       "      <th>neighbor_income</th>\n",
       "      <th>age</th>\n",
       "      <th>marketing_permit</th>\n",
       "      <th>urban_ic</th>\n",
       "      <th>dining_ic</th>\n",
       "      <th>presidential</th>\n",
       "      <th>client_segment</th>\n",
       "      <th>sect_empl</th>\n",
       "      <th>prev_stay</th>\n",
       "      <th>prev_all_in_stay</th>\n",
       "      <th>divorce</th>\n",
       "      <th>fam_adult_size</th>\n",
       "      <th>children_no</th>\n",
       "      <th>tenure_mts</th>\n",
       "      <th>tenure_yrs</th>\n",
       "      <th>company_ic</th>\n",
       "      <th>claims_no</th>\n",
       "      <th>claims_am</th>\n",
       "      <th>nights_booked</th>\n",
       "      <th>shop_am</th>\n",
       "      <th>shop_use</th>\n",
       "      <th>retired</th>\n",
       "      <th>gold_status</th>\n",
       "      <th>score1_pos</th>\n",
       "      <th>score1_neg</th>\n",
       "      <th>score2_pos</th>\n",
       "      <th>score2_neg</th>\n",
       "      <th>score3_pos</th>\n",
       "      <th>score3_neg</th>\n",
       "      <th>score4_pos</th>\n",
       "      <th>score4_neg</th>\n",
       "      <th>score5_pos</th>\n",
       "      <th>score5_neg</th>\n",
       "      <th>outcome_profit</th>\n",
       "      <th>outcome_damage_inc</th>\n",
       "      <th>outcome_damage_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4954.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4970.000000</td>\n",
       "      <td>4999.000000</td>\n",
       "      <td>4912.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4761.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4912.000000</td>\n",
       "      <td>4912.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4608.000000</td>\n",
       "      <td>4608.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4973.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4912.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>1.225000e+03</td>\n",
       "      <td>1.314000e+03</td>\n",
       "      <td>1.209000e+03</td>\n",
       "      <td>1.304000e+03</td>\n",
       "      <td>1.261000e+03</td>\n",
       "      <td>1.367000e+03</td>\n",
       "      <td>1.223000e+03</td>\n",
       "      <td>1.324000e+03</td>\n",
       "      <td>1.232000e+03</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2281.260158</td>\n",
       "      <td>696.057712</td>\n",
       "      <td>3637.900950</td>\n",
       "      <td>145.952967</td>\n",
       "      <td>0.352335</td>\n",
       "      <td>3298.716394</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0.024661</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.390944</td>\n",
       "      <td>0.401811</td>\n",
       "      <td>0.024205</td>\n",
       "      <td>6.051507</td>\n",
       "      <td>5.646250</td>\n",
       "      <td>0.287043</td>\n",
       "      <td>32778.558916</td>\n",
       "      <td>44.901152</td>\n",
       "      <td>0.495452</td>\n",
       "      <td>0.883970</td>\n",
       "      <td>0.049267</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>1.298565</td>\n",
       "      <td>0.213463</td>\n",
       "      <td>0.889832</td>\n",
       "      <td>0.252678</td>\n",
       "      <td>0.102486</td>\n",
       "      <td>1.960986</td>\n",
       "      <td>0.385082</td>\n",
       "      <td>273.111545</td>\n",
       "      <td>22.780165</td>\n",
       "      <td>0.018597</td>\n",
       "      <td>0.218314</td>\n",
       "      <td>121.078826</td>\n",
       "      <td>28.992521</td>\n",
       "      <td>403.019960</td>\n",
       "      <td>0.151873</td>\n",
       "      <td>0.182131</td>\n",
       "      <td>0.034769</td>\n",
       "      <td>4.997356e-01</td>\n",
       "      <td>5.003663e-01</td>\n",
       "      <td>4.985522e-01</td>\n",
       "      <td>4.967340e-01</td>\n",
       "      <td>4.942801e-01</td>\n",
       "      <td>4.985876e-01</td>\n",
       "      <td>4.962065e-01</td>\n",
       "      <td>5.013962e-01</td>\n",
       "      <td>5.009593e-01</td>\n",
       "      <td>5.192953</td>\n",
       "      <td>1967.310930</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>189.970736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8365.254507</td>\n",
       "      <td>3051.119275</td>\n",
       "      <td>5726.625669</td>\n",
       "      <td>581.068095</td>\n",
       "      <td>0.889449</td>\n",
       "      <td>4549.646039</td>\n",
       "      <td>0.198858</td>\n",
       "      <td>0.155107</td>\n",
       "      <td>0.292134</td>\n",
       "      <td>0.488011</td>\n",
       "      <td>0.490313</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>3.112104</td>\n",
       "      <td>5.052513</td>\n",
       "      <td>0.452427</td>\n",
       "      <td>6858.671948</td>\n",
       "      <td>16.225094</td>\n",
       "      <td>0.500030</td>\n",
       "      <td>0.320293</td>\n",
       "      <td>0.216447</td>\n",
       "      <td>0.065252</td>\n",
       "      <td>0.800831</td>\n",
       "      <td>0.826006</td>\n",
       "      <td>0.313130</td>\n",
       "      <td>0.434592</td>\n",
       "      <td>0.303317</td>\n",
       "      <td>0.805545</td>\n",
       "      <td>0.832933</td>\n",
       "      <td>152.498416</td>\n",
       "      <td>12.719429</td>\n",
       "      <td>0.135111</td>\n",
       "      <td>0.712408</td>\n",
       "      <td>1783.146726</td>\n",
       "      <td>37.480510</td>\n",
       "      <td>1335.935144</td>\n",
       "      <td>0.358934</td>\n",
       "      <td>0.385991</td>\n",
       "      <td>0.183212</td>\n",
       "      <td>2.879255e-01</td>\n",
       "      <td>2.887168e-01</td>\n",
       "      <td>2.877572e-01</td>\n",
       "      <td>2.897994e-01</td>\n",
       "      <td>2.899165e-01</td>\n",
       "      <td>2.877292e-01</td>\n",
       "      <td>2.886538e-01</td>\n",
       "      <td>2.876226e-01</td>\n",
       "      <td>2.901323e-01</td>\n",
       "      <td>3.159868</td>\n",
       "      <td>1371.061266</td>\n",
       "      <td>0.436129</td>\n",
       "      <td>379.005941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-7.871775</td>\n",
       "      <td>10.680000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>229.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1638.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28630.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.520205e-01</td>\n",
       "      <td>2.510338e-01</td>\n",
       "      <td>2.521282e-01</td>\n",
       "      <td>2.454209e-01</td>\n",
       "      <td>2.405574e-01</td>\n",
       "      <td>2.495061e-01</td>\n",
       "      <td>2.474100e-01</td>\n",
       "      <td>2.506703e-01</td>\n",
       "      <td>2.514905e-01</td>\n",
       "      <td>3.124958</td>\n",
       "      <td>1333.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>469.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1889.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31990.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.974162e-01</td>\n",
       "      <td>4.986215e-01</td>\n",
       "      <td>4.987791e-01</td>\n",
       "      <td>4.985832e-01</td>\n",
       "      <td>4.942465e-01</td>\n",
       "      <td>5.016458e-01</td>\n",
       "      <td>4.933486e-01</td>\n",
       "      <td>5.020603e-01</td>\n",
       "      <td>5.029121e-01</td>\n",
       "      <td>5.188006</td>\n",
       "      <td>1721.235000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1688.000000</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>3165.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35924.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>368.250000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.487276e-01</td>\n",
       "      <td>7.516726e-01</td>\n",
       "      <td>7.441403e-01</td>\n",
       "      <td>7.474935e-01</td>\n",
       "      <td>7.449235e-01</td>\n",
       "      <td>7.464826e-01</td>\n",
       "      <td>7.452133e-01</td>\n",
       "      <td>7.493876e-01</td>\n",
       "      <td>7.512817e-01</td>\n",
       "      <td>7.357425</td>\n",
       "      <td>2223.712500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>202.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>360577.000000</td>\n",
       "      <td>150537.000000</td>\n",
       "      <td>100577.000000</td>\n",
       "      <td>14866.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>104984.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>90587.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>12098.364339</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.986510e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.993125e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>14.776319</td>\n",
       "      <td>31529.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3157.240000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           income_am  profit_last_am      profit_am     damage_am  \\\n",
       "count    4947.000000     4947.000000    4947.000000   4954.000000   \n",
       "mean     2281.260158      696.057712    3637.900950    145.952967   \n",
       "std      8365.254507     3051.119275    5726.625669    581.068095   \n",
       "min         0.000000        0.000000       0.000000      0.000000   \n",
       "25%       229.000000        0.000000    1638.000000      0.000000   \n",
       "50%       469.000000       52.000000    1889.000000      0.000000   \n",
       "75%      1688.000000      810.000000    3165.500000      0.000000   \n",
       "max    360577.000000   150537.000000  100577.000000  14866.000000   \n",
       "\n",
       "        damage_inc   crd_lim_rec  credit_use_ic    gluten_ic   lactose_ic  \\\n",
       "count  4947.000000   4947.000000    4947.000000  4947.000000  4947.000000   \n",
       "mean      0.352335   3298.716394       0.041237     0.024661     0.094199   \n",
       "std       0.889449   4549.646039       0.198858     0.155107     0.292134   \n",
       "min       0.000000      0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000      0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000   1500.000000       0.000000     0.000000     0.000000   \n",
       "75%       0.000000   5000.000000       0.000000     0.000000     0.000000   \n",
       "max      10.000000  30000.000000       1.000000     1.000000     1.000000   \n",
       "\n",
       "       insurance_ic       spa_ic      empl_ic  cab_requests       bar_no  \\\n",
       "count   4947.000000  4970.000000  4999.000000   4912.000000  4947.000000   \n",
       "mean       0.390944     0.401811     0.024205      6.051507     5.646250   \n",
       "std        0.488011     0.490313     0.153700      3.112104     5.052513   \n",
       "min        0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "25%        0.000000     0.000000     0.000000      3.000000     2.000000   \n",
       "50%        0.000000     0.000000     0.000000      6.000000     5.000000   \n",
       "75%        1.000000     1.000000     0.000000      9.000000     8.000000   \n",
       "max        1.000000     1.000000     1.000000     16.000000   111.000000   \n",
       "\n",
       "          sport_ic  neighbor_income          age  marketing_permit  \\\n",
       "count  4947.000000      4761.000000  4947.000000       4947.000000   \n",
       "mean      0.287043     32778.558916    44.901152          0.495452   \n",
       "std       0.452427      6858.671948    16.225094          0.500030   \n",
       "min       0.000000         0.000000    16.000000          0.000000   \n",
       "25%       0.000000     28630.000000    31.000000          0.000000   \n",
       "50%       0.000000     31990.000000    45.000000          0.000000   \n",
       "75%       1.000000     35924.000000    57.000000          1.000000   \n",
       "max       1.000000    104984.000000    97.000000          1.000000   \n",
       "\n",
       "          urban_ic    dining_ic  presidential  client_segment    sect_empl  \\\n",
       "count  4947.000000  4912.000000   4912.000000     4947.000000  4947.000000   \n",
       "mean      0.883970     0.049267      0.004275        1.298565     0.213463   \n",
       "std       0.320293     0.216447      0.065252        0.800831     0.826006   \n",
       "min       0.000000     0.000000      0.000000        0.000000     0.000000   \n",
       "25%       1.000000     0.000000      0.000000        1.000000     0.000000   \n",
       "50%       1.000000     0.000000      0.000000        1.000000     0.000000   \n",
       "75%       1.000000     0.000000      0.000000        2.000000     0.000000   \n",
       "max       1.000000     1.000000      1.000000        5.000000     6.000000   \n",
       "\n",
       "         prev_stay  prev_all_in_stay      divorce  fam_adult_size  \\\n",
       "count  4947.000000       4947.000000  4947.000000     4947.000000   \n",
       "mean      0.889832          0.252678     0.102486        1.960986   \n",
       "std       0.313130          0.434592     0.303317        0.805545   \n",
       "min       0.000000          0.000000     0.000000        1.000000   \n",
       "25%       1.000000          0.000000     0.000000        1.000000   \n",
       "50%       1.000000          0.000000     0.000000        2.000000   \n",
       "75%       1.000000          1.000000     0.000000        3.000000   \n",
       "max       1.000000          1.000000     1.000000        4.000000   \n",
       "\n",
       "       children_no   tenure_mts   tenure_yrs   company_ic    claims_no  \\\n",
       "count  4947.000000  4608.000000  4608.000000  4947.000000  4947.000000   \n",
       "mean      0.385082   273.111545    22.780165     0.018597     0.218314   \n",
       "std       0.832933   152.498416    12.719429     0.135111     0.712408   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000   154.000000    13.000000     0.000000     0.000000   \n",
       "50%       0.000000   271.000000    23.000000     0.000000     0.000000   \n",
       "75%       0.000000   368.250000    31.000000     0.000000     0.000000   \n",
       "max       6.000000   679.000000    57.000000     1.000000     9.000000   \n",
       "\n",
       "          claims_am  nights_booked       shop_am     shop_use      retired  \\\n",
       "count   4973.000000    4947.000000   4947.000000  4912.000000  4947.000000   \n",
       "mean     121.078826      28.992521    403.019960     0.151873     0.182131   \n",
       "std     1783.146726      37.480510   1335.935144     0.358934     0.385991   \n",
       "min        0.000000       1.000000      0.000000     0.000000     0.000000   \n",
       "25%        0.000000       4.000000      0.000000     0.000000     0.000000   \n",
       "50%        0.000000      11.000000      0.000000     0.000000     0.000000   \n",
       "75%        0.000000      45.000000      0.000000     0.000000     0.000000   \n",
       "max    90587.000000     375.000000  12098.364339     1.000000     1.000000   \n",
       "\n",
       "       gold_status    score1_pos    score1_neg    score2_pos    score2_neg  \\\n",
       "count  4947.000000  1.225000e+03  1.314000e+03  1.209000e+03  1.304000e+03   \n",
       "mean      0.034769  4.997356e-01  5.003663e-01  4.985522e-01  4.967340e-01   \n",
       "std       0.183212  2.879255e-01  2.887168e-01  2.877572e-01  2.897994e-01   \n",
       "min       0.000000  1.000000e-07  1.000000e-07  1.000000e-07  1.000000e-07   \n",
       "25%       0.000000  2.520205e-01  2.510338e-01  2.521282e-01  2.454209e-01   \n",
       "50%       0.000000  4.974162e-01  4.986215e-01  4.987791e-01  4.985832e-01   \n",
       "75%       0.000000  7.487276e-01  7.516726e-01  7.441403e-01  7.474935e-01   \n",
       "max       1.000000  9.999999e-01  9.999999e-01  9.999999e-01  9.986510e-01   \n",
       "\n",
       "         score3_pos    score3_neg    score4_pos    score4_neg    score5_pos  \\\n",
       "count  1.261000e+03  1.367000e+03  1.223000e+03  1.324000e+03  1.232000e+03   \n",
       "mean   4.942801e-01  4.985876e-01  4.962065e-01  5.013962e-01  5.009593e-01   \n",
       "std    2.899165e-01  2.877292e-01  2.886538e-01  2.876226e-01  2.901323e-01   \n",
       "min    1.000000e-07  1.000000e-07  1.000000e-07  1.000000e-07  1.000000e-07   \n",
       "25%    2.405574e-01  2.495061e-01  2.474100e-01  2.506703e-01  2.514905e-01   \n",
       "50%    4.942465e-01  5.016458e-01  4.933486e-01  5.020603e-01  5.029121e-01   \n",
       "75%    7.449235e-01  7.464826e-01  7.452133e-01  7.493876e-01  7.512817e-01   \n",
       "max    9.999999e-01  9.999999e-01  9.999999e-01  9.993125e-01  9.999999e-01   \n",
       "\n",
       "        score5_neg  outcome_profit  outcome_damage_inc  outcome_damage_amount  \n",
       "count  1493.000000     5000.000000         5000.000000            5000.000000  \n",
       "mean      5.192953     1967.310930            0.255400             189.970736  \n",
       "std       3.159868     1371.061266            0.436129             379.005941  \n",
       "min      -7.871775       10.680000            0.000000               0.000000  \n",
       "25%       3.124958     1333.320000            0.000000               0.000000  \n",
       "50%       5.188006     1721.235000            0.000000               0.000000  \n",
       "75%       7.357425     2223.712500            1.000000             202.612500  \n",
       "max      14.776319    31529.000000            1.000000            3157.240000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.head())\n",
    "pd.options.display.max_columns = None\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90      47\n",
       "306     48\n",
       "474     47\n",
       "517     47\n",
       "670     47\n",
       "790     47\n",
       "996     48\n",
       "1062    47\n",
       "1164    46\n",
       "1261    47\n",
       "1275    47\n",
       "1281    46\n",
       "1338    46\n",
       "1448    47\n",
       "1696    47\n",
       "1744    48\n",
       "1852    47\n",
       "2058    47\n",
       "2096    47\n",
       "2250    47\n",
       "2348    48\n",
       "2672    48\n",
       "2696    47\n",
       "2734    47\n",
       "2917    47\n",
       "2956    46\n",
       "3068    48\n",
       "3198    46\n",
       "3213    47\n",
       "3326    46\n",
       "3377    48\n",
       "3494    46\n",
       "3793    47\n",
       "3926    46\n",
       "3952    47\n",
       "3959    47\n",
       "3990    47\n",
       "4000    47\n",
       "4009    46\n",
       "4138    47\n",
       "4159    47\n",
       "4242    47\n",
       "4392    47\n",
       "4477    47\n",
       "4528    46\n",
       "4545    48\n",
       "4614    47\n",
       "4641    48\n",
       "4669    46\n",
       "4789    47\n",
       "4851    47\n",
       "4946    47\n",
       "4993    47\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.isnull().sum(axis=1))[data.isnull().sum(axis=1) > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['income_am', 'profit_last_am', 'profit_am', 'damage_am', 'damage_inc',\n",
       "       'crd_lim_rec', 'credit_use_ic', 'gluten_ic', 'lactose_ic',\n",
       "       'insurance_ic', 'spa_ic', 'empl_ic', 'cab_requests', 'married_cd',\n",
       "       'bar_no', 'sport_ic', 'neighbor_income', 'age', 'marketing_permit',\n",
       "       'urban_ic', 'dining_ic', 'presidential', 'client_segment', 'sect_empl',\n",
       "       'prev_stay', 'prev_all_in_stay', 'divorce', 'fam_adult_size',\n",
       "       'children_no', 'tenure_mts', 'tenure_yrs', 'company_ic', 'claims_no',\n",
       "       'claims_am', 'nights_booked', 'gender', 'shop_am', 'shop_use',\n",
       "       'retired', 'gold_status', 'score1_pos', 'score1_neg', 'score2_pos',\n",
       "       'score2_neg', 'score3_pos', 'score3_neg', 'score4_pos', 'score4_neg',\n",
       "       'score5_pos', 'score5_neg', 'outcome_profit', 'outcome_damage_inc',\n",
       "       'outcome_damage_amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 53)\n",
      "(5000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data_feat = data.drop(['outcome_profit', 'outcome_damage_inc', 'outcome_damage_amount'], axis=1)\n",
    "print(data_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 50)\n",
      "(500, 50)\n",
      "(5500, 50)\n"
     ]
    }
   ],
   "source": [
    "print(data_feat.shape)\n",
    "print(score.shape)\n",
    "datafull = pd.concat([data_feat, score])\n",
    "print(datafull.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think about some potentially categorical features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    3712\n",
      "2.0     925\n",
      "0.0     352\n",
      "3.0     329\n",
      "4.0      87\n",
      "5.0      38\n",
      "Name: client_segment, dtype: int64\n",
      "0.0    4820\n",
      "1.0     468\n",
      "6.0      78\n",
      "2.0      45\n",
      "4.0      29\n",
      "3.0       3\n",
      "Name: sect_empl, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "M    2734\n",
       "V    2709\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(datafull['client_segment'].value_counts())\n",
    "print(datafull['sect_empl'].value_counts())\n",
    "datafull['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dummify them. I'm going to make the missing a separate category - not sure whether that is better than e.g. a mode imputation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_segment_0.0</th>\n",
       "      <th>client_segment_1.0</th>\n",
       "      <th>client_segment_2.0</th>\n",
       "      <th>client_segment_3.0</th>\n",
       "      <th>client_segment_4.0</th>\n",
       "      <th>client_segment_5.0</th>\n",
       "      <th>client_segment_nan</th>\n",
       "      <th>sect_empl_0.0</th>\n",
       "      <th>sect_empl_1.0</th>\n",
       "      <th>sect_empl_2.0</th>\n",
       "      <th>sect_empl_3.0</th>\n",
       "      <th>sect_empl_4.0</th>\n",
       "      <th>sect_empl_6.0</th>\n",
       "      <th>sect_empl_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_segment_0.0  client_segment_1.0  client_segment_2.0  \\\n",
       "0                   0                   1                   0   \n",
       "1                   0                   1                   0   \n",
       "2                   0                   1                   0   \n",
       "3                   0                   1                   0   \n",
       "4                   0                   0                   1   \n",
       "\n",
       "   client_segment_3.0  client_segment_4.0  client_segment_5.0  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   client_segment_nan  sect_empl_0.0  sect_empl_1.0  sect_empl_2.0  \\\n",
       "0                   0              0              1              0   \n",
       "1                   0              1              0              0   \n",
       "2                   0              1              0              0   \n",
       "3                   0              1              0              0   \n",
       "4                   0              1              0              0   \n",
       "\n",
       "   sect_empl_3.0  sect_empl_4.0  sect_empl_6.0  sect_empl_nan  \n",
       "0              0              0              0              0  \n",
       "1              0              0              0              0  \n",
       "2              0              0              0              0  \n",
       "3              0              0              0              0  \n",
       "4              0              0              0              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafull['client_segment'] = pd.Categorical(datafull['client_segment'])\n",
    "datafull['sect_empl'] = pd.Categorical(datafull['sect_empl'])\n",
    "pd.get_dummies(datafull[['client_segment', 'sect_empl']], dummy_na=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5500, 50)\n",
      "(5500, 67)\n"
     ]
    }
   ],
   "source": [
    "print(datafull.shape)\n",
    "datafull2 = pd.concat([datafull,pd.get_dummies(datafull[['gender','client_segment', 'sect_empl']], dummy_na=True)], axis=1)\n",
    "print(datafull2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will stop here, but depending on which types of models you will use, it might be a good idea to remove the original features (or perhaps its better to explicitly keep them?), and perhaps also one dummy? Up to you, but I remove the original features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['income_am', 'profit_last_am', 'profit_am', 'damage_am', 'damage_inc',\n",
       "       'crd_lim_rec', 'credit_use_ic', 'gluten_ic', 'lactose_ic',\n",
       "       'insurance_ic', 'spa_ic', 'empl_ic', 'cab_requests', 'married_cd',\n",
       "       'bar_no', 'sport_ic', 'neighbor_income', 'age', 'marketing_permit',\n",
       "       'urban_ic', 'dining_ic', 'presidential', 'client_segment', 'sect_empl',\n",
       "       'prev_stay', 'prev_all_in_stay', 'divorce', 'fam_adult_size',\n",
       "       'children_no', 'tenure_mts', 'tenure_yrs', 'company_ic', 'claims_no',\n",
       "       'claims_am', 'nights_booked', 'gender', 'shop_am', 'shop_use',\n",
       "       'retired', 'gold_status', 'score1_pos', 'score1_neg', 'score2_pos',\n",
       "       'score2_neg', 'score3_pos', 'score3_neg', 'score4_pos', 'score4_neg',\n",
       "       'score5_pos', 'score5_neg', 'gender_M', 'gender_V', 'gender_nan',\n",
       "       'client_segment_0.0', 'client_segment_1.0', 'client_segment_2.0',\n",
       "       'client_segment_3.0', 'client_segment_4.0', 'client_segment_5.0',\n",
       "       'client_segment_nan', 'sect_empl_0.0', 'sect_empl_1.0', 'sect_empl_2.0',\n",
       "       'sect_empl_3.0', 'sect_empl_4.0', 'sect_empl_6.0', 'sect_empl_nan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafull2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5500, 67)\n",
      "(5500, 64)\n"
     ]
    }
   ],
   "source": [
    "print(datafull2.shape)\n",
    "datafull2.drop(['client_segment', 'sect_empl', 'gender'], axis=1, inplace=True)\n",
    "print(datafull2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will give one example of a simple engineered feature: profit per night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafull2['profitpernight'] = datafull2['profit_am'] / datafull2['nights_booked']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then there are of course missing values. There is much to be gained or lost by having a good approach here. I keep it simple: I remove features with too many missings (say, more than 30%?), and I remove observations with too many missings (say, more than 30%?) The remainder receives a very simple mean imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score1_pos    0.755091\n",
       "score1_neg    0.736727\n",
       "score2_pos    0.760000\n",
       "score2_neg    0.740364\n",
       "score3_pos    0.746000\n",
       "score3_neg    0.725091\n",
       "score4_pos    0.756000\n",
       "score4_neg    0.736364\n",
       "score5_pos    0.752000\n",
       "score5_neg    0.700545\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5500, 65)\n",
      "(5500, 55)\n"
     ]
    }
   ],
   "source": [
    "print(datafull2.shape)\n",
    "datafull2.dropna(thresh = datafull2.shape[0]*0.3, axis = 1, inplace = True)\n",
    "print(datafull2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is slightly worrisome that these are all score columns. Perhaps you can find a better way to deal with this?\n",
    "\n",
    "Just changing the axis allows to remove observations with too many missings. Here none meet our criterion of more than 30% missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5500, 55)\n",
      "(5500, 55)\n"
     ]
    }
   ],
   "source": [
    "print(datafull2.shape)\n",
    "datafull2.dropna(thresh = datafull2.shape[1]*0.3, axis = 0, inplace = True)\n",
    "print(datafull2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now do a mean impute - which may or may not be optimal, with all those binary features... If you check out the code datafull2.isnull().sum(), you will see that the outcome has no missings, which is of course a good thing, we can just run the imputation through..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3086\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(datafull2.isnull().sum().sum())\n",
    "datafull2.fillna(datafull2.mean(), inplace=True)\n",
    "print(datafull2.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we rescale all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "datafull3 = pd.DataFrame(scaler.fit_transform(datafull2))\n",
    "datafull3.columns = datafull2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step, we separate the data sets again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 58)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 55)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data[['outcome_profit', 'outcome_damage_inc', 'outcome_damage_amount']],datafull3[0:5000]], axis=1)\n",
    "print(data.shape)\n",
    "score = datafull3[5000:5500]\n",
    "score.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for profit\n",
    "I'm not going to be too fancy with data splitting: a plain train/test split, and then within train a CV for hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(['outcome_profit', 'outcome_damage_inc', 'outcome_damage_amount'],1), \n",
    "                                                    data['outcome_profit'], test_size=0.2, random_state=29949)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being my lazy self, I just steal the code from the practical, with some minor changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 10.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.4,\n",
       " 'n_estimators': 577,\n",
       " 'min_samples_split': 30,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 9,\n",
       " 'learning_rate': 0.016611473712508432}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 50)]\n",
    "learning_rate = [x for x in np.logspace(start = -3, stop = -0.01, num = 50)]\n",
    "max_features = ['auto']\n",
    "max_depth = [int(x) for x in np.linspace(1, 10, num = 10)]\n",
    "min_samples_split = [2, 5, 10, 30]\n",
    "min_samples_leaf = [1, 2, 4, 10, 30]\n",
    "subsample = [0.4, 0.6, 0.8, 1]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'learning_rate': learning_rate,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'subsample': subsample}\n",
    "gbm = GradientBoostingRegressor()\n",
    "gbm_random = RandomizedSearchCV(estimator = gbm, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=4872, n_jobs = -1)\n",
    "gbm_random.fit(X_train, y_train)\n",
    "gbm_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the final model for profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.920\n",
      "R2: 0.752\n"
     ]
    }
   ],
   "source": [
    "params = gbm_random.best_params_\n",
    "gbm_profit = GradientBoostingRegressor(**params)\n",
    "gbm_profit.fit(X_train, y_train)\n",
    "print('R2: %.3f' % gbm_profit.score(X_train, np.array(y_train).reshape(-1,1)))\n",
    "print('R2: %.3f' % gbm_profit.score(X_test, np.array(y_test).reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now don't forget to score the 500 potential guests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_preds = gbm_profit.predict(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanations of the model internals can really follow the practical on white-boxing, I won't do it here. Instead, I move straight on to the...\n",
    "\n",
    "### Model for damage (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3723\n",
       "1    1277\n",
       "Name: outcome_damage_inc, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.outcome_damage_inc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 10.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.6,\n",
       " 'n_estimators': 1000,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 4,\n",
       " 'learning_rate': 0.004075717570257835}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(['outcome_profit', 'outcome_damage_inc', 'outcome_damage_amount'],1), \n",
    "                                                    data['outcome_damage_inc'], test_size=0.2, random_state=9876)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 50)]\n",
    "learning_rate = [x for x in np.logspace(start = -3, stop = -0.01, num = 50)]\n",
    "max_features = ['auto']\n",
    "max_depth = [int(x) for x in np.linspace(1, 10, num = 10)]\n",
    "min_samples_split = [2, 5, 10, 30]\n",
    "min_samples_leaf = [1, 2, 4, 10, 30]\n",
    "subsample = [0.4, 0.6, 0.8, 1]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'learning_rate': learning_rate,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'subsample': subsample}\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm_random = RandomizedSearchCV(estimator = gbm, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=4872, n_jobs = -1)\n",
    "gbm_random.fit(X_train, y_train)\n",
    "gbm_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.797\n",
      "Test accuracy: 0.736\n"
     ]
    }
   ],
   "source": [
    "params = gbm_random.best_params_\n",
    "gbm_damagebin = GradientBoostingClassifier(**params)\n",
    "gbm_damagebin.fit(X_train, y_train)\n",
    "print('Train accuracy: %.3f' % gbm_damagebin.score(X_train, y_train))\n",
    "print('Test accuracy: %.3f' % gbm_damagebin.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "damagebin_preds = gbm_damagebin.predict_proba(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I did not do any effort at all to think about the issues we discussed in the session about binary data. I know you can do a better job here! Myself, on the other hand, I'm gonna move on.\n",
    "\n",
    "### Model for damage (amount)\n",
    "For this, you may want to take care. I already know from the model above who is going to cause damage, so do I want to predict the damage amount for just anyone? No! I want to predict it only for those who actually cause damage, and so I only train it in those that caused damage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1277, 58)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_dam = data[data.outcome_damage_inc == 1]\n",
    "data_dam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.4,\n",
       " 'n_estimators': 412,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 30,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 8,\n",
       " 'learning_rate': 0.009469488710361799}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_dam.drop(['outcome_profit', 'outcome_damage_inc', 'outcome_damage_amount'],1), \n",
    "                                                    data_dam['outcome_damage_amount'], test_size=0.2, random_state=29949)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 50)]\n",
    "learning_rate = [x for x in np.logspace(start = -3, stop = -0.01, num = 50)]\n",
    "max_features = ['auto']\n",
    "max_depth = [int(x) for x in np.linspace(1, 10, num = 10)]\n",
    "min_samples_split = [2, 5, 10, 30]\n",
    "min_samples_leaf = [1, 2, 4, 10, 30]\n",
    "subsample = [0.4, 0.6, 0.8, 1]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'learning_rate': learning_rate,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'subsample': subsample}\n",
    "gbm = GradientBoostingRegressor()\n",
    "gbm_random = RandomizedSearchCV(estimator = gbm, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=4872, n_jobs = -1)\n",
    "gbm_random.fit(X_train, y_train)\n",
    "gbm_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.371\n",
      "R2: 0.088\n"
     ]
    }
   ],
   "source": [
    "params = gbm_random.best_params_\n",
    "gbm_damageam = GradientBoostingRegressor(**params)\n",
    "gbm_damageam.fit(X_train, y_train)\n",
    "print('R2: %.3f' % gbm_damageam.score(X_train, np.array(y_train).reshape(-1,1)))\n",
    "print('R2: %.3f' % gbm_damageam.score(X_test, np.array(y_test).reshape(-1,1)))\n",
    "damageam_preds = gbm_damageam.predict(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fieuw, not such a good model! Still, it's up to you to consider whether this is good enough, and what could be better. Me, with my minimal solution, I'm already done! I now works towards a criterion for ranking clients. I am going to subtract the expected damages from the expected profit, but you may want to do something else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1255.529809\n",
       "1      2152.721999\n",
       "2       966.632632\n",
       "3      1891.705241\n",
       "4      1350.787637\n",
       "          ...     \n",
       "495    1973.134300\n",
       "496    3108.621444\n",
       "497    1606.019345\n",
       "498    1742.387598\n",
       "499    1242.793813\n",
       "Length: 500, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(profit_preds - [x[1] for x in damagebin_preds] * damageam_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-035d056a5132>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  score['exp_profit'] = exp_profit\n"
     ]
    }
   ],
   "source": [
    "exp_profit = pd.Series(profit_preds - [x[1] for x in damagebin_preds] * damageam_preds)\n",
    "exp_profit.index = score.index\n",
    "score['exp_profit'] = exp_profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I select the best of the potential client list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income_am</th>\n",
       "      <th>profit_last_am</th>\n",
       "      <th>profit_am</th>\n",
       "      <th>damage_am</th>\n",
       "      <th>damage_inc</th>\n",
       "      <th>crd_lim_rec</th>\n",
       "      <th>credit_use_ic</th>\n",
       "      <th>gluten_ic</th>\n",
       "      <th>lactose_ic</th>\n",
       "      <th>insurance_ic</th>\n",
       "      <th>spa_ic</th>\n",
       "      <th>empl_ic</th>\n",
       "      <th>cab_requests</th>\n",
       "      <th>married_cd</th>\n",
       "      <th>bar_no</th>\n",
       "      <th>sport_ic</th>\n",
       "      <th>neighbor_income</th>\n",
       "      <th>age</th>\n",
       "      <th>marketing_permit</th>\n",
       "      <th>urban_ic</th>\n",
       "      <th>dining_ic</th>\n",
       "      <th>presidential</th>\n",
       "      <th>prev_stay</th>\n",
       "      <th>prev_all_in_stay</th>\n",
       "      <th>divorce</th>\n",
       "      <th>fam_adult_size</th>\n",
       "      <th>children_no</th>\n",
       "      <th>tenure_mts</th>\n",
       "      <th>tenure_yrs</th>\n",
       "      <th>company_ic</th>\n",
       "      <th>claims_no</th>\n",
       "      <th>claims_am</th>\n",
       "      <th>nights_booked</th>\n",
       "      <th>shop_am</th>\n",
       "      <th>shop_use</th>\n",
       "      <th>retired</th>\n",
       "      <th>gold_status</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>gender_V</th>\n",
       "      <th>gender_nan</th>\n",
       "      <th>client_segment_0.0</th>\n",
       "      <th>client_segment_1.0</th>\n",
       "      <th>client_segment_2.0</th>\n",
       "      <th>client_segment_3.0</th>\n",
       "      <th>client_segment_4.0</th>\n",
       "      <th>client_segment_5.0</th>\n",
       "      <th>client_segment_nan</th>\n",
       "      <th>sect_empl_0.0</th>\n",
       "      <th>sect_empl_1.0</th>\n",
       "      <th>sect_empl_2.0</th>\n",
       "      <th>sect_empl_3.0</th>\n",
       "      <th>sect_empl_4.0</th>\n",
       "      <th>sect_empl_6.0</th>\n",
       "      <th>sect_empl_nan</th>\n",
       "      <th>profitpernight</th>\n",
       "      <th>exp_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5081</th>\n",
       "      <td>1.940324</td>\n",
       "      <td>0.088783</td>\n",
       "      <td>4.673283</td>\n",
       "      <td>-0.257888</td>\n",
       "      <td>-0.400697</td>\n",
       "      <td>-0.729723</td>\n",
       "      <td>-0.206795</td>\n",
       "      <td>-0.159701</td>\n",
       "      <td>-0.323565</td>\n",
       "      <td>-0.804458</td>\n",
       "      <td>-0.814459</td>\n",
       "      <td>-0.154389</td>\n",
       "      <td>0.965341</td>\n",
       "      <td>-2.070860</td>\n",
       "      <td>-0.731548</td>\n",
       "      <td>-0.636862</td>\n",
       "      <td>1.254833</td>\n",
       "      <td>1.934358</td>\n",
       "      <td>1.014313</td>\n",
       "      <td>-2.766034</td>\n",
       "      <td>-0.229867</td>\n",
       "      <td>-0.064465</td>\n",
       "      <td>0.352159</td>\n",
       "      <td>-0.585555</td>\n",
       "      <td>-0.340079</td>\n",
       "      <td>-1.205512</td>\n",
       "      <td>-0.463093</td>\n",
       "      <td>-1.689418</td>\n",
       "      <td>-1.703415</td>\n",
       "      <td>-0.136819</td>\n",
       "      <td>-0.306211</td>\n",
       "      <td>-0.066991</td>\n",
       "      <td>-0.746039</td>\n",
       "      <td>-0.303011</td>\n",
       "      <td>-0.427959</td>\n",
       "      <td>2.135877</td>\n",
       "      <td>-0.197347</td>\n",
       "      <td>-0.994199</td>\n",
       "      <td>1.015022</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>-0.261488</td>\n",
       "      <td>-1.440855</td>\n",
       "      <td>-0.449651</td>\n",
       "      <td>3.964508</td>\n",
       "      <td>-0.126777</td>\n",
       "      <td>-0.08341</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>0.375605</td>\n",
       "      <td>-0.304967</td>\n",
       "      <td>-0.090826</td>\n",
       "      <td>-0.023361</td>\n",
       "      <td>-0.072806</td>\n",
       "      <td>-0.119941</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>24.250550</td>\n",
       "      <td>18299.753737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2.224194</td>\n",
       "      <td>-0.195415</td>\n",
       "      <td>5.415988</td>\n",
       "      <td>-0.257888</td>\n",
       "      <td>0.727014</td>\n",
       "      <td>-0.729723</td>\n",
       "      <td>-0.206795</td>\n",
       "      <td>-0.159701</td>\n",
       "      <td>-0.323565</td>\n",
       "      <td>-0.804458</td>\n",
       "      <td>-0.814459</td>\n",
       "      <td>-0.154389</td>\n",
       "      <td>-1.314814</td>\n",
       "      <td>0.482891</td>\n",
       "      <td>-0.329548</td>\n",
       "      <td>-0.636862</td>\n",
       "      <td>-0.881735</td>\n",
       "      <td>0.071430</td>\n",
       "      <td>1.014313</td>\n",
       "      <td>0.365314</td>\n",
       "      <td>-0.229867</td>\n",
       "      <td>-0.064465</td>\n",
       "      <td>0.352159</td>\n",
       "      <td>-0.585555</td>\n",
       "      <td>-0.340079</td>\n",
       "      <td>1.295575</td>\n",
       "      <td>-0.463093</td>\n",
       "      <td>-0.611296</td>\n",
       "      <td>-0.639747</td>\n",
       "      <td>-0.136819</td>\n",
       "      <td>6.798247</td>\n",
       "      <td>-0.066991</td>\n",
       "      <td>-0.666020</td>\n",
       "      <td>-0.303011</td>\n",
       "      <td>-0.427959</td>\n",
       "      <td>-0.473095</td>\n",
       "      <td>5.120278</td>\n",
       "      <td>1.005835</td>\n",
       "      <td>-0.985200</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>-0.261488</td>\n",
       "      <td>-1.440855</td>\n",
       "      <td>-0.449651</td>\n",
       "      <td>3.964508</td>\n",
       "      <td>-0.126777</td>\n",
       "      <td>-0.08341</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>-2.662374</td>\n",
       "      <td>3.279045</td>\n",
       "      <td>-0.090826</td>\n",
       "      <td>-0.023361</td>\n",
       "      <td>-0.072806</td>\n",
       "      <td>-0.119941</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>6.578927</td>\n",
       "      <td>8634.701816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5256</th>\n",
       "      <td>2.648173</td>\n",
       "      <td>-0.226306</td>\n",
       "      <td>5.536532</td>\n",
       "      <td>0.389627</td>\n",
       "      <td>2.982435</td>\n",
       "      <td>0.814962</td>\n",
       "      <td>-0.206795</td>\n",
       "      <td>-0.159701</td>\n",
       "      <td>3.122937</td>\n",
       "      <td>-0.804458</td>\n",
       "      <td>1.234994</td>\n",
       "      <td>-0.154389</td>\n",
       "      <td>-0.989077</td>\n",
       "      <td>0.482891</td>\n",
       "      <td>0.072453</td>\n",
       "      <td>1.586641</td>\n",
       "      <td>-0.924991</td>\n",
       "      <td>0.257723</td>\n",
       "      <td>1.014313</td>\n",
       "      <td>0.365314</td>\n",
       "      <td>-0.229867</td>\n",
       "      <td>15.779189</td>\n",
       "      <td>0.352159</td>\n",
       "      <td>1.725667</td>\n",
       "      <td>-0.340079</td>\n",
       "      <td>1.295575</td>\n",
       "      <td>-0.463093</td>\n",
       "      <td>0.589650</td>\n",
       "      <td>0.587562</td>\n",
       "      <td>-0.136819</td>\n",
       "      <td>3.956464</td>\n",
       "      <td>-0.066991</td>\n",
       "      <td>-0.425961</td>\n",
       "      <td>6.983459</td>\n",
       "      <td>2.376861</td>\n",
       "      <td>-0.473095</td>\n",
       "      <td>5.120278</td>\n",
       "      <td>1.005835</td>\n",
       "      <td>-0.985200</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>-0.261488</td>\n",
       "      <td>-1.440855</td>\n",
       "      <td>-0.449651</td>\n",
       "      <td>3.964508</td>\n",
       "      <td>-0.126777</td>\n",
       "      <td>-0.08341</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>0.375605</td>\n",
       "      <td>-0.304967</td>\n",
       "      <td>-0.090826</td>\n",
       "      <td>-0.023361</td>\n",
       "      <td>-0.072806</td>\n",
       "      <td>-0.119941</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>1.747839</td>\n",
       "      <td>8424.161449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>2.553630</td>\n",
       "      <td>-0.050570</td>\n",
       "      <td>3.054425</td>\n",
       "      <td>-0.257888</td>\n",
       "      <td>-0.400697</td>\n",
       "      <td>0.814962</td>\n",
       "      <td>-0.206795</td>\n",
       "      <td>-0.159701</td>\n",
       "      <td>-0.323565</td>\n",
       "      <td>-0.804458</td>\n",
       "      <td>-0.814459</td>\n",
       "      <td>-0.154389</td>\n",
       "      <td>-0.989077</td>\n",
       "      <td>0.482891</td>\n",
       "      <td>0.474454</td>\n",
       "      <td>1.586641</td>\n",
       "      <td>-0.879173</td>\n",
       "      <td>1.561772</td>\n",
       "      <td>1.014313</td>\n",
       "      <td>-2.766034</td>\n",
       "      <td>-0.229867</td>\n",
       "      <td>-0.064465</td>\n",
       "      <td>0.352159</td>\n",
       "      <td>-0.585555</td>\n",
       "      <td>-0.340079</td>\n",
       "      <td>-1.205512</td>\n",
       "      <td>-0.463093</td>\n",
       "      <td>0.753416</td>\n",
       "      <td>0.751203</td>\n",
       "      <td>-0.136819</td>\n",
       "      <td>-0.306211</td>\n",
       "      <td>-0.066991</td>\n",
       "      <td>-0.666020</td>\n",
       "      <td>-0.303011</td>\n",
       "      <td>-0.427959</td>\n",
       "      <td>2.135877</td>\n",
       "      <td>5.120278</td>\n",
       "      <td>1.005835</td>\n",
       "      <td>-0.985200</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>-0.261488</td>\n",
       "      <td>-1.440855</td>\n",
       "      <td>-0.449651</td>\n",
       "      <td>3.964508</td>\n",
       "      <td>-0.126777</td>\n",
       "      <td>-0.08341</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>0.375605</td>\n",
       "      <td>-0.304967</td>\n",
       "      <td>-0.090826</td>\n",
       "      <td>-0.023361</td>\n",
       "      <td>-0.072806</td>\n",
       "      <td>-0.119941</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>3.836675</td>\n",
       "      <td>7686.753629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078</th>\n",
       "      <td>0.160589</td>\n",
       "      <td>-0.139468</td>\n",
       "      <td>0.656452</td>\n",
       "      <td>-0.257888</td>\n",
       "      <td>1.854724</td>\n",
       "      <td>2.580316</td>\n",
       "      <td>-0.206795</td>\n",
       "      <td>6.327267</td>\n",
       "      <td>3.122937</td>\n",
       "      <td>1.256090</td>\n",
       "      <td>1.234994</td>\n",
       "      <td>-0.154389</td>\n",
       "      <td>0.639605</td>\n",
       "      <td>0.482891</td>\n",
       "      <td>3.489459</td>\n",
       "      <td>1.586641</td>\n",
       "      <td>1.263424</td>\n",
       "      <td>0.071430</td>\n",
       "      <td>-0.996213</td>\n",
       "      <td>0.365314</td>\n",
       "      <td>-0.229867</td>\n",
       "      <td>-0.064465</td>\n",
       "      <td>0.352159</td>\n",
       "      <td>1.725667</td>\n",
       "      <td>-0.340079</td>\n",
       "      <td>1.295575</td>\n",
       "      <td>1.945520</td>\n",
       "      <td>1.394830</td>\n",
       "      <td>1.405769</td>\n",
       "      <td>-0.136819</td>\n",
       "      <td>-0.306211</td>\n",
       "      <td>-0.066991</td>\n",
       "      <td>-0.746039</td>\n",
       "      <td>2.226833</td>\n",
       "      <td>2.376861</td>\n",
       "      <td>-0.473095</td>\n",
       "      <td>5.120278</td>\n",
       "      <td>1.005835</td>\n",
       "      <td>-0.985200</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>-0.261488</td>\n",
       "      <td>-1.440855</td>\n",
       "      <td>2.223948</td>\n",
       "      <td>-0.252238</td>\n",
       "      <td>-0.126777</td>\n",
       "      <td>-0.08341</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>0.375605</td>\n",
       "      <td>-0.304967</td>\n",
       "      <td>-0.090826</td>\n",
       "      <td>-0.023361</td>\n",
       "      <td>-0.072806</td>\n",
       "      <td>-0.119941</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>5.593145</td>\n",
       "      <td>7636.364925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5084</th>\n",
       "      <td>0.553987</td>\n",
       "      <td>0.334195</td>\n",
       "      <td>0.803155</td>\n",
       "      <td>2.625056</td>\n",
       "      <td>7.493277</td>\n",
       "      <td>0.594293</td>\n",
       "      <td>4.886349</td>\n",
       "      <td>-0.159701</td>\n",
       "      <td>3.122937</td>\n",
       "      <td>1.256090</td>\n",
       "      <td>1.234994</td>\n",
       "      <td>-0.154389</td>\n",
       "      <td>0.639605</td>\n",
       "      <td>0.482891</td>\n",
       "      <td>-0.329548</td>\n",
       "      <td>1.586641</td>\n",
       "      <td>0.063112</td>\n",
       "      <td>-0.735839</td>\n",
       "      <td>1.014313</td>\n",
       "      <td>0.365314</td>\n",
       "      <td>-0.229867</td>\n",
       "      <td>-0.064465</td>\n",
       "      <td>0.352159</td>\n",
       "      <td>-0.585555</td>\n",
       "      <td>-0.340079</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>-0.463093</td>\n",
       "      <td>-1.150357</td>\n",
       "      <td>-1.130671</td>\n",
       "      <td>-0.136819</td>\n",
       "      <td>-0.306211</td>\n",
       "      <td>-0.066991</td>\n",
       "      <td>-0.746039</td>\n",
       "      <td>-0.303011</td>\n",
       "      <td>-0.427959</td>\n",
       "      <td>-0.473095</td>\n",
       "      <td>5.120278</td>\n",
       "      <td>-0.994199</td>\n",
       "      <td>1.015022</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>-0.261488</td>\n",
       "      <td>0.694032</td>\n",
       "      <td>-0.449651</td>\n",
       "      <td>-0.252238</td>\n",
       "      <td>-0.126777</td>\n",
       "      <td>-0.08341</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>0.375605</td>\n",
       "      <td>-0.304967</td>\n",
       "      <td>-0.090826</td>\n",
       "      <td>-0.023361</td>\n",
       "      <td>-0.072806</td>\n",
       "      <td>-0.119941</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>6.274551</td>\n",
       "      <td>7429.107987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5253</th>\n",
       "      <td>2.975172</td>\n",
       "      <td>-0.171389</td>\n",
       "      <td>3.029327</td>\n",
       "      <td>-0.257888</td>\n",
       "      <td>-0.400697</td>\n",
       "      <td>-0.729723</td>\n",
       "      <td>-0.206795</td>\n",
       "      <td>-0.159701</td>\n",
       "      <td>3.122937</td>\n",
       "      <td>-0.804458</td>\n",
       "      <td>-0.814459</td>\n",
       "      <td>-0.154389</td>\n",
       "      <td>-0.337604</td>\n",
       "      <td>0.482891</td>\n",
       "      <td>0.474454</td>\n",
       "      <td>-0.636862</td>\n",
       "      <td>0.782184</td>\n",
       "      <td>0.257723</td>\n",
       "      <td>1.014313</td>\n",
       "      <td>0.365314</td>\n",
       "      <td>-0.229867</td>\n",
       "      <td>-0.064465</td>\n",
       "      <td>0.352159</td>\n",
       "      <td>1.725667</td>\n",
       "      <td>-0.340079</td>\n",
       "      <td>1.295575</td>\n",
       "      <td>3.149827</td>\n",
       "      <td>-0.065411</td>\n",
       "      <td>-0.067003</td>\n",
       "      <td>-0.136819</td>\n",
       "      <td>-0.306211</td>\n",
       "      <td>-0.066991</td>\n",
       "      <td>-0.666020</td>\n",
       "      <td>-0.303011</td>\n",
       "      <td>-0.427959</td>\n",
       "      <td>-0.473095</td>\n",
       "      <td>5.120278</td>\n",
       "      <td>1.005835</td>\n",
       "      <td>-0.985200</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>-0.261488</td>\n",
       "      <td>-1.440855</td>\n",
       "      <td>-0.449651</td>\n",
       "      <td>3.964508</td>\n",
       "      <td>-0.126777</td>\n",
       "      <td>-0.08341</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>-2.662374</td>\n",
       "      <td>3.279045</td>\n",
       "      <td>-0.090826</td>\n",
       "      <td>-0.023361</td>\n",
       "      <td>-0.072806</td>\n",
       "      <td>-0.119941</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>3.807531</td>\n",
       "      <td>7345.124401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5074</th>\n",
       "      <td>1.568977</td>\n",
       "      <td>1.100638</td>\n",
       "      <td>1.288865</td>\n",
       "      <td>-0.257888</td>\n",
       "      <td>-0.400697</td>\n",
       "      <td>1.918308</td>\n",
       "      <td>-0.206795</td>\n",
       "      <td>-0.159701</td>\n",
       "      <td>-0.323565</td>\n",
       "      <td>-0.804458</td>\n",
       "      <td>-0.814459</td>\n",
       "      <td>-0.154389</td>\n",
       "      <td>0.639605</td>\n",
       "      <td>0.482891</td>\n",
       "      <td>0.876455</td>\n",
       "      <td>1.586641</td>\n",
       "      <td>0.755658</td>\n",
       "      <td>0.878699</td>\n",
       "      <td>1.014313</td>\n",
       "      <td>0.365314</td>\n",
       "      <td>-0.229867</td>\n",
       "      <td>-0.064465</td>\n",
       "      <td>0.352159</td>\n",
       "      <td>1.725667</td>\n",
       "      <td>-0.340079</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>-0.463093</td>\n",
       "      <td>0.835298</td>\n",
       "      <td>0.833024</td>\n",
       "      <td>-0.136819</td>\n",
       "      <td>-0.306211</td>\n",
       "      <td>-0.066991</td>\n",
       "      <td>-0.692693</td>\n",
       "      <td>7.088669</td>\n",
       "      <td>2.376861</td>\n",
       "      <td>-0.473095</td>\n",
       "      <td>5.120278</td>\n",
       "      <td>1.005835</td>\n",
       "      <td>-0.985200</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>-0.261488</td>\n",
       "      <td>-1.440855</td>\n",
       "      <td>-0.449651</td>\n",
       "      <td>3.964508</td>\n",
       "      <td>-0.126777</td>\n",
       "      <td>-0.08341</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>0.375605</td>\n",
       "      <td>-0.304967</td>\n",
       "      <td>-0.090826</td>\n",
       "      <td>-0.023361</td>\n",
       "      <td>-0.072806</td>\n",
       "      <td>-0.119941</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>2.535846</td>\n",
       "      <td>7164.207410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>-0.023744</td>\n",
       "      <td>0.538591</td>\n",
       "      <td>0.151652</td>\n",
       "      <td>-0.257888</td>\n",
       "      <td>-0.400697</td>\n",
       "      <td>-0.729723</td>\n",
       "      <td>-0.206795</td>\n",
       "      <td>-0.159701</td>\n",
       "      <td>3.122937</td>\n",
       "      <td>1.256090</td>\n",
       "      <td>1.234994</td>\n",
       "      <td>-0.154389</td>\n",
       "      <td>-1.314814</td>\n",
       "      <td>0.482891</td>\n",
       "      <td>0.675454</td>\n",
       "      <td>-0.636862</td>\n",
       "      <td>-0.239981</td>\n",
       "      <td>0.754504</td>\n",
       "      <td>1.014313</td>\n",
       "      <td>0.365314</td>\n",
       "      <td>-0.229867</td>\n",
       "      <td>-0.064465</td>\n",
       "      <td>0.352159</td>\n",
       "      <td>-0.585555</td>\n",
       "      <td>-0.340079</td>\n",
       "      <td>-1.205512</td>\n",
       "      <td>-0.463093</td>\n",
       "      <td>-0.215530</td>\n",
       "      <td>-0.230644</td>\n",
       "      <td>-0.136819</td>\n",
       "      <td>-0.306211</td>\n",
       "      <td>-0.066991</td>\n",
       "      <td>-0.746039</td>\n",
       "      <td>-0.303011</td>\n",
       "      <td>-0.427959</td>\n",
       "      <td>2.135877</td>\n",
       "      <td>-0.197347</td>\n",
       "      <td>1.005835</td>\n",
       "      <td>-0.985200</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>-0.261488</td>\n",
       "      <td>-1.440855</td>\n",
       "      <td>2.223948</td>\n",
       "      <td>-0.252238</td>\n",
       "      <td>-0.126777</td>\n",
       "      <td>-0.08341</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>0.375605</td>\n",
       "      <td>-0.304967</td>\n",
       "      <td>-0.090826</td>\n",
       "      <td>-0.023361</td>\n",
       "      <td>-0.072806</td>\n",
       "      <td>-0.119941</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>3.248449</td>\n",
       "      <td>6405.388470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5124</th>\n",
       "      <td>0.314220</td>\n",
       "      <td>-0.236947</td>\n",
       "      <td>0.869613</td>\n",
       "      <td>0.356105</td>\n",
       "      <td>0.727014</td>\n",
       "      <td>0.152954</td>\n",
       "      <td>-0.206795</td>\n",
       "      <td>-0.159701</td>\n",
       "      <td>3.122937</td>\n",
       "      <td>1.256090</td>\n",
       "      <td>1.234994</td>\n",
       "      <td>-0.154389</td>\n",
       "      <td>-0.989077</td>\n",
       "      <td>-2.070860</td>\n",
       "      <td>0.273454</td>\n",
       "      <td>-0.636862</td>\n",
       "      <td>0.216542</td>\n",
       "      <td>0.630308</td>\n",
       "      <td>1.014313</td>\n",
       "      <td>0.365314</td>\n",
       "      <td>-0.229867</td>\n",
       "      <td>-0.064465</td>\n",
       "      <td>0.352159</td>\n",
       "      <td>1.725667</td>\n",
       "      <td>2.971284</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>-0.463093</td>\n",
       "      <td>-0.188235</td>\n",
       "      <td>-0.148823</td>\n",
       "      <td>-0.136819</td>\n",
       "      <td>-0.306211</td>\n",
       "      <td>-0.066991</td>\n",
       "      <td>-0.692693</td>\n",
       "      <td>-0.303011</td>\n",
       "      <td>-0.427959</td>\n",
       "      <td>-0.473095</td>\n",
       "      <td>5.120278</td>\n",
       "      <td>1.005835</td>\n",
       "      <td>-0.985200</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>-0.261488</td>\n",
       "      <td>-1.440855</td>\n",
       "      <td>2.223948</td>\n",
       "      <td>-0.252238</td>\n",
       "      <td>-0.126777</td>\n",
       "      <td>-0.08341</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>0.375605</td>\n",
       "      <td>-0.304967</td>\n",
       "      <td>-0.090826</td>\n",
       "      <td>-0.023361</td>\n",
       "      <td>-0.072806</td>\n",
       "      <td>-0.119941</td>\n",
       "      <td>-0.102334</td>\n",
       "      <td>1.886731</td>\n",
       "      <td>4589.281798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      income_am  profit_last_am  profit_am  damage_am  damage_inc  \\\n",
       "5081   1.940324        0.088783   4.673283  -0.257888   -0.400697   \n",
       "5431   2.224194       -0.195415   5.415988  -0.257888    0.727014   \n",
       "5256   2.648173       -0.226306   5.536532   0.389627    2.982435   \n",
       "5048   2.553630       -0.050570   3.054425  -0.257888   -0.400697   \n",
       "5078   0.160589       -0.139468   0.656452  -0.257888    1.854724   \n",
       "5084   0.553987        0.334195   0.803155   2.625056    7.493277   \n",
       "5253   2.975172       -0.171389   3.029327  -0.257888   -0.400697   \n",
       "5074   1.568977        1.100638   1.288865  -0.257888   -0.400697   \n",
       "5149  -0.023744        0.538591   0.151652  -0.257888   -0.400697   \n",
       "5124   0.314220       -0.236947   0.869613   0.356105    0.727014   \n",
       "\n",
       "      crd_lim_rec  credit_use_ic  gluten_ic  lactose_ic  insurance_ic  \\\n",
       "5081    -0.729723      -0.206795  -0.159701   -0.323565     -0.804458   \n",
       "5431    -0.729723      -0.206795  -0.159701   -0.323565     -0.804458   \n",
       "5256     0.814962      -0.206795  -0.159701    3.122937     -0.804458   \n",
       "5048     0.814962      -0.206795  -0.159701   -0.323565     -0.804458   \n",
       "5078     2.580316      -0.206795   6.327267    3.122937      1.256090   \n",
       "5084     0.594293       4.886349  -0.159701    3.122937      1.256090   \n",
       "5253    -0.729723      -0.206795  -0.159701    3.122937     -0.804458   \n",
       "5074     1.918308      -0.206795  -0.159701   -0.323565     -0.804458   \n",
       "5149    -0.729723      -0.206795  -0.159701    3.122937      1.256090   \n",
       "5124     0.152954      -0.206795  -0.159701    3.122937      1.256090   \n",
       "\n",
       "        spa_ic   empl_ic  cab_requests  married_cd    bar_no  sport_ic  \\\n",
       "5081 -0.814459 -0.154389      0.965341   -2.070860 -0.731548 -0.636862   \n",
       "5431 -0.814459 -0.154389     -1.314814    0.482891 -0.329548 -0.636862   \n",
       "5256  1.234994 -0.154389     -0.989077    0.482891  0.072453  1.586641   \n",
       "5048 -0.814459 -0.154389     -0.989077    0.482891  0.474454  1.586641   \n",
       "5078  1.234994 -0.154389      0.639605    0.482891  3.489459  1.586641   \n",
       "5084  1.234994 -0.154389      0.639605    0.482891 -0.329548  1.586641   \n",
       "5253 -0.814459 -0.154389     -0.337604    0.482891  0.474454 -0.636862   \n",
       "5074 -0.814459 -0.154389      0.639605    0.482891  0.876455  1.586641   \n",
       "5149  1.234994 -0.154389     -1.314814    0.482891  0.675454 -0.636862   \n",
       "5124  1.234994 -0.154389     -0.989077   -2.070860  0.273454 -0.636862   \n",
       "\n",
       "      neighbor_income       age  marketing_permit  urban_ic  dining_ic  \\\n",
       "5081         1.254833  1.934358          1.014313 -2.766034  -0.229867   \n",
       "5431        -0.881735  0.071430          1.014313  0.365314  -0.229867   \n",
       "5256        -0.924991  0.257723          1.014313  0.365314  -0.229867   \n",
       "5048        -0.879173  1.561772          1.014313 -2.766034  -0.229867   \n",
       "5078         1.263424  0.071430         -0.996213  0.365314  -0.229867   \n",
       "5084         0.063112 -0.735839          1.014313  0.365314  -0.229867   \n",
       "5253         0.782184  0.257723          1.014313  0.365314  -0.229867   \n",
       "5074         0.755658  0.878699          1.014313  0.365314  -0.229867   \n",
       "5149        -0.239981  0.754504          1.014313  0.365314  -0.229867   \n",
       "5124         0.216542  0.630308          1.014313  0.365314  -0.229867   \n",
       "\n",
       "      presidential  prev_stay  prev_all_in_stay   divorce  fam_adult_size  \\\n",
       "5081     -0.064465   0.352159         -0.585555 -0.340079       -1.205512   \n",
       "5431     -0.064465   0.352159         -0.585555 -0.340079        1.295575   \n",
       "5256     15.779189   0.352159          1.725667 -0.340079        1.295575   \n",
       "5048     -0.064465   0.352159         -0.585555 -0.340079       -1.205512   \n",
       "5078     -0.064465   0.352159          1.725667 -0.340079        1.295575   \n",
       "5084     -0.064465   0.352159         -0.585555 -0.340079        0.045032   \n",
       "5253     -0.064465   0.352159          1.725667 -0.340079        1.295575   \n",
       "5074     -0.064465   0.352159          1.725667 -0.340079        0.045032   \n",
       "5149     -0.064465   0.352159         -0.585555 -0.340079       -1.205512   \n",
       "5124     -0.064465   0.352159          1.725667  2.971284        0.045032   \n",
       "\n",
       "      children_no  tenure_mts  tenure_yrs  company_ic  claims_no  claims_am  \\\n",
       "5081    -0.463093   -1.689418   -1.703415   -0.136819  -0.306211  -0.066991   \n",
       "5431    -0.463093   -0.611296   -0.639747   -0.136819   6.798247  -0.066991   \n",
       "5256    -0.463093    0.589650    0.587562   -0.136819   3.956464  -0.066991   \n",
       "5048    -0.463093    0.753416    0.751203   -0.136819  -0.306211  -0.066991   \n",
       "5078     1.945520    1.394830    1.405769   -0.136819  -0.306211  -0.066991   \n",
       "5084    -0.463093   -1.150357   -1.130671   -0.136819  -0.306211  -0.066991   \n",
       "5253     3.149827   -0.065411   -0.067003   -0.136819  -0.306211  -0.066991   \n",
       "5074    -0.463093    0.835298    0.833024   -0.136819  -0.306211  -0.066991   \n",
       "5149    -0.463093   -0.215530   -0.230644   -0.136819  -0.306211  -0.066991   \n",
       "5124    -0.463093   -0.188235   -0.148823   -0.136819  -0.306211  -0.066991   \n",
       "\n",
       "      nights_booked   shop_am  shop_use   retired  gold_status  gender_M  \\\n",
       "5081      -0.746039 -0.303011 -0.427959  2.135877    -0.197347 -0.994199   \n",
       "5431      -0.666020 -0.303011 -0.427959 -0.473095     5.120278  1.005835   \n",
       "5256      -0.425961  6.983459  2.376861 -0.473095     5.120278  1.005835   \n",
       "5048      -0.666020 -0.303011 -0.427959  2.135877     5.120278  1.005835   \n",
       "5078      -0.746039  2.226833  2.376861 -0.473095     5.120278  1.005835   \n",
       "5084      -0.746039 -0.303011 -0.427959 -0.473095     5.120278 -0.994199   \n",
       "5253      -0.666020 -0.303011 -0.427959 -0.473095     5.120278  1.005835   \n",
       "5074      -0.692693  7.088669  2.376861 -0.473095     5.120278  1.005835   \n",
       "5149      -0.746039 -0.303011 -0.427959  2.135877    -0.197347  1.005835   \n",
       "5124      -0.692693 -0.303011 -0.427959 -0.473095     5.120278  1.005835   \n",
       "\n",
       "      gender_V  gender_nan  client_segment_0.0  client_segment_1.0  \\\n",
       "5081  1.015022   -0.102334           -0.261488           -1.440855   \n",
       "5431 -0.985200   -0.102334           -0.261488           -1.440855   \n",
       "5256 -0.985200   -0.102334           -0.261488           -1.440855   \n",
       "5048 -0.985200   -0.102334           -0.261488           -1.440855   \n",
       "5078 -0.985200   -0.102334           -0.261488           -1.440855   \n",
       "5084  1.015022   -0.102334           -0.261488            0.694032   \n",
       "5253 -0.985200   -0.102334           -0.261488           -1.440855   \n",
       "5074 -0.985200   -0.102334           -0.261488           -1.440855   \n",
       "5149 -0.985200   -0.102334           -0.261488           -1.440855   \n",
       "5124 -0.985200   -0.102334           -0.261488           -1.440855   \n",
       "\n",
       "      client_segment_2.0  client_segment_3.0  client_segment_4.0  \\\n",
       "5081           -0.449651            3.964508           -0.126777   \n",
       "5431           -0.449651            3.964508           -0.126777   \n",
       "5256           -0.449651            3.964508           -0.126777   \n",
       "5048           -0.449651            3.964508           -0.126777   \n",
       "5078            2.223948           -0.252238           -0.126777   \n",
       "5084           -0.449651           -0.252238           -0.126777   \n",
       "5253           -0.449651            3.964508           -0.126777   \n",
       "5074           -0.449651            3.964508           -0.126777   \n",
       "5149            2.223948           -0.252238           -0.126777   \n",
       "5124            2.223948           -0.252238           -0.126777   \n",
       "\n",
       "      client_segment_5.0  client_segment_nan  sect_empl_0.0  sect_empl_1.0  \\\n",
       "5081            -0.08341           -0.102334       0.375605      -0.304967   \n",
       "5431            -0.08341           -0.102334      -2.662374       3.279045   \n",
       "5256            -0.08341           -0.102334       0.375605      -0.304967   \n",
       "5048            -0.08341           -0.102334       0.375605      -0.304967   \n",
       "5078            -0.08341           -0.102334       0.375605      -0.304967   \n",
       "5084            -0.08341           -0.102334       0.375605      -0.304967   \n",
       "5253            -0.08341           -0.102334      -2.662374       3.279045   \n",
       "5074            -0.08341           -0.102334       0.375605      -0.304967   \n",
       "5149            -0.08341           -0.102334       0.375605      -0.304967   \n",
       "5124            -0.08341           -0.102334       0.375605      -0.304967   \n",
       "\n",
       "      sect_empl_2.0  sect_empl_3.0  sect_empl_4.0  sect_empl_6.0  \\\n",
       "5081      -0.090826      -0.023361      -0.072806      -0.119941   \n",
       "5431      -0.090826      -0.023361      -0.072806      -0.119941   \n",
       "5256      -0.090826      -0.023361      -0.072806      -0.119941   \n",
       "5048      -0.090826      -0.023361      -0.072806      -0.119941   \n",
       "5078      -0.090826      -0.023361      -0.072806      -0.119941   \n",
       "5084      -0.090826      -0.023361      -0.072806      -0.119941   \n",
       "5253      -0.090826      -0.023361      -0.072806      -0.119941   \n",
       "5074      -0.090826      -0.023361      -0.072806      -0.119941   \n",
       "5149      -0.090826      -0.023361      -0.072806      -0.119941   \n",
       "5124      -0.090826      -0.023361      -0.072806      -0.119941   \n",
       "\n",
       "      sect_empl_nan  profitpernight    exp_profit  \n",
       "5081      -0.102334       24.250550  18299.753737  \n",
       "5431      -0.102334        6.578927   8634.701816  \n",
       "5256      -0.102334        1.747839   8424.161449  \n",
       "5048      -0.102334        3.836675   7686.753629  \n",
       "5078      -0.102334        5.593145   7636.364925  \n",
       "5084      -0.102334        6.274551   7429.107987  \n",
       "5253      -0.102334        3.807531   7345.124401  \n",
       "5074      -0.102334        2.535846   7164.207410  \n",
       "5149      -0.102334        3.248449   6405.388470  \n",
       "5124      -0.102334        1.886731   4589.281798  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.sort_values('exp_profit', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
