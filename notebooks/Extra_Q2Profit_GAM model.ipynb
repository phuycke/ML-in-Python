{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85821755",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Final project of the course Machine Learning with Python 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f72520b",
   "metadata": {},
   "source": [
    "For the final project, it is asked to create a client list. There is a data set with information over the profit and damage caused by 5000 russian customers. Then there is another data set with a list of applicants. The goal is to create a list of 200 customers that offers a balance between the anticipated damages and profit. There is a recommended list of 5 steps that could be used (but it is not obligatory to follow), to have the list. A minimal solution was also offered to serve as a guide and to reduce ambiguity. \n",
    "\n",
    "Possible steps:\n",
    "1) prepare the data set\n",
    "\n",
    "    • briefly survey the data\n",
    "    • deal with data issues:\n",
    "    • appropriately handle categorical data\n",
    "    • treat missing data\n",
    "    • identify outliers, and choose whether or not to make your analysis more robust by removing these.\n",
    "\n",
    "2) predict the projected revenue per clients\n",
    "\n",
    "    • choose an algorithm, and train it in an optimal way\n",
    "    • score the 500 applicants\n",
    "\n",
    "3) predict which clients will cause damage\n",
    "\n",
    "    • choose an algorithm, and train it in an optimal way\n",
    "    • score the 500 applicants\n",
    "\n",
    "4) for those that will wreak havoc, predict the amount of damage they will cause\n",
    "\n",
    "    • choose an algorithm, and train it in an optimal way\n",
    "    • score the 500 applicants\n",
    "\n",
    "5) create a measure of the expected value of each applicant, and create an optimal selection of 200 guests\n",
    "\n",
    "For the development of the project it was decided to use the proposed steps and and use the solution as a guide, to build upon it. Also, as the team was working on the code at the same time, a Github repository was created to facilitate this. The first step that was carried out was Preprocessing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5aefda",
   "metadata": {},
   "source": [
    "## 1. Preprocessing de data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dccf5e",
   "metadata": {},
   "source": [
    "First of all, the libraries need to be imported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41bc3e4c",
   "metadata": {
    "title": "I mport the libraries"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import animation as ani, pyplot as plt\n",
    "import seaborn as sns #pretty graphics R style\n",
    "\n",
    "from IPython.display import HTML\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt #graphics\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler #library for the rescaling\n",
    "import statsmodels.api as sm \n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from treeinterpreter import treeinterpreter as ti, utils\n",
    "import joblib\n",
    "import getpass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e0592",
   "metadata": {},
   "source": [
    "To avoid changing the directory everytime a different team member ran the code, the following was created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d70e7498",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Load data"
   },
   "outputs": [],
   "source": [
    "if getpass.getuser() == 'daniel':\n",
    "    project_root_path = Path(\"//home/daniel/Projects/Python ML Pipeline\")\n",
    "    data_raw_path = project_root_path / 'data' / 'raw'\n",
    "    data_output_path = project_root_path / 'data' / 'processed'\n",
    "    # Lets read the training dataset\n",
    "    data_train = pd.read_csv(data_raw_path / 'train_V2.csv')\n",
    "    # Now we read the data set of the potential clients\n",
    "    score = pd.read_csv(data_raw_path /  'score.csv')\n",
    "    # We read the dictonary\n",
    "    dict_features = pd.read_csv(data_raw_path /  'dictionary.csv', delimiter=';', header=None)\n",
    "    \n",
    "elif getpass.getuser() == 'maart':\n",
    "    data_file_path = \"C:/Users/maart/Machine Learning/ML-in-Python/data/raw/\"\n",
    "    # Lets read the trining dataset\n",
    "    data_train = pd.read_csv(data_file_path+'train_V2.csv')\n",
    "    # Now we read the training data set\n",
    "    score = pd.read_csv(data_file_path+'score.csv')\n",
    "    dict_features_path = data_file_path+'dictionary.csv'\n",
    "    dict_features = pd.read_csv(dict_features_path, delimiter=';', header=None)\n",
    "    \n",
    "else:\n",
    "    project_root_path = Path(\"C:/Users/mhinojosalee/Documents/GitHub/ML-in-Python\")\n",
    "    data_raw_path = project_root_path / 'data' / 'raw'\n",
    "    data_output_path = project_root_path / 'data' / 'processed'\n",
    "    # Lets read the training dataset\n",
    "    data_train = pd.read_csv(data_raw_path / 'train_V2.csv')\n",
    "    # Now we read the data set of the potential clients\n",
    "    score = pd.read_csv(data_raw_path /  'score.csv')\n",
    "    # We read the dictonary\n",
    "    dict_features = pd.read_csv(data_raw_path /  'dictionary.csv', delimiter=';', header=None)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaf8ae9",
   "metadata": {},
   "source": [
    "Some visualization tasks were carried out to get more acquintence with the data. This information can be consulted in====>>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c3e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b40a6cb",
   "metadata": {},
   "source": [
    "Now, lets show the data set columns as it is, with their columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8779a8ea",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Basic things to visualize the data"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income_am</th>\n",
       "      <th>profit_last_am</th>\n",
       "      <th>profit_am</th>\n",
       "      <th>damage_am</th>\n",
       "      <th>damage_inc</th>\n",
       "      <th>crd_lim_rec</th>\n",
       "      <th>credit_use_ic</th>\n",
       "      <th>gluten_ic</th>\n",
       "      <th>lactose_ic</th>\n",
       "      <th>insurance_ic</th>\n",
       "      <th>spa_ic</th>\n",
       "      <th>empl_ic</th>\n",
       "      <th>cab_requests</th>\n",
       "      <th>married_cd</th>\n",
       "      <th>bar_no</th>\n",
       "      <th>sport_ic</th>\n",
       "      <th>neighbor_income</th>\n",
       "      <th>age</th>\n",
       "      <th>marketing_permit</th>\n",
       "      <th>urban_ic</th>\n",
       "      <th>dining_ic</th>\n",
       "      <th>presidential</th>\n",
       "      <th>client_segment</th>\n",
       "      <th>sect_empl</th>\n",
       "      <th>prev_stay</th>\n",
       "      <th>prev_all_in_stay</th>\n",
       "      <th>divorce</th>\n",
       "      <th>fam_adult_size</th>\n",
       "      <th>children_no</th>\n",
       "      <th>tenure_mts</th>\n",
       "      <th>tenure_yrs</th>\n",
       "      <th>company_ic</th>\n",
       "      <th>claims_no</th>\n",
       "      <th>claims_am</th>\n",
       "      <th>nights_booked</th>\n",
       "      <th>gender</th>\n",
       "      <th>shop_am</th>\n",
       "      <th>shop_use</th>\n",
       "      <th>retired</th>\n",
       "      <th>gold_status</th>\n",
       "      <th>score1_pos</th>\n",
       "      <th>score1_neg</th>\n",
       "      <th>score2_pos</th>\n",
       "      <th>score2_neg</th>\n",
       "      <th>score3_pos</th>\n",
       "      <th>score3_neg</th>\n",
       "      <th>score4_pos</th>\n",
       "      <th>score4_neg</th>\n",
       "      <th>score5_pos</th>\n",
       "      <th>score5_neg</th>\n",
       "      <th>outcome_profit</th>\n",
       "      <th>outcome_damage_inc</th>\n",
       "      <th>outcome_damage_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>227.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3201.0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28936.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467768</td>\n",
       "      <td>0.98334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838147</td>\n",
       "      <td>0.082288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1791.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>268.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1682.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16674.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.955259</td>\n",
       "      <td>1672.78</td>\n",
       "      <td>1</td>\n",
       "      <td>829.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>283.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1673.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32552.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.232375</td>\n",
       "      <td>0.099529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.101955</td>\n",
       "      <td>1.743020</td>\n",
       "      <td>1001.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32252.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.889793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1785.59</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4091.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>3425.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29605.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>V</td>\n",
       "      <td>1454.210627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.330503</td>\n",
       "      <td>0.766294</td>\n",
       "      <td>0.490486</td>\n",
       "      <td>0.542445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3140.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   income_am  profit_last_am  profit_am  damage_am  damage_inc  crd_lim_rec  \\\n",
       "0      227.0             0.0     3201.0      888.0         6.0      15000.0   \n",
       "1      268.0            16.0     1682.0        0.0         0.0        750.0   \n",
       "2      283.0            23.0     1673.0        0.0         0.0        750.0   \n",
       "3      227.0             0.0     1685.0        0.0         0.0          0.0   \n",
       "4     4091.0          1028.0     3425.0      785.0         2.0      14000.0   \n",
       "\n",
       "   credit_use_ic  gluten_ic  lactose_ic  insurance_ic  spa_ic  empl_ic  \\\n",
       "0            0.0        0.0         0.0           0.0     1.0      0.0   \n",
       "1            0.0        0.0         0.0           1.0     1.0      0.0   \n",
       "2            0.0        0.0         0.0           1.0     0.0      0.0   \n",
       "3            0.0        0.0         0.0           0.0     0.0      0.0   \n",
       "4            0.0        0.0         1.0           0.0     1.0      0.0   \n",
       "\n",
       "   cab_requests  married_cd  bar_no  sport_ic  neighbor_income   age  \\\n",
       "0           3.0        True     2.0       1.0          28936.0  37.0   \n",
       "1           7.0        True     3.0       0.0          16674.0  18.0   \n",
       "2           1.0        True     4.0       0.0          32552.0  21.0   \n",
       "3           6.0        True     8.0       1.0          32252.0  37.0   \n",
       "4           4.0       False     2.0       1.0          29605.0  26.0   \n",
       "\n",
       "   marketing_permit  urban_ic  dining_ic  presidential  client_segment  \\\n",
       "0               0.0       1.0        0.0           0.0             1.0   \n",
       "1               0.0       0.0        0.0           0.0             1.0   \n",
       "2               0.0       1.0        0.0           0.0             1.0   \n",
       "3               0.0       1.0        0.0           0.0             1.0   \n",
       "4               0.0       1.0        0.0           0.0             2.0   \n",
       "\n",
       "   sect_empl  prev_stay  prev_all_in_stay  divorce  fam_adult_size  \\\n",
       "0        1.0        1.0               1.0      0.0             3.0   \n",
       "1        0.0        0.0               0.0      0.0             1.0   \n",
       "2        0.0        1.0               0.0      0.0             1.0   \n",
       "3        0.0        1.0               0.0      0.0             3.0   \n",
       "4        0.0        1.0               0.0      0.0             2.0   \n",
       "\n",
       "   children_no  tenure_mts  tenure_yrs  company_ic  claims_no  claims_am  \\\n",
       "0          2.0       476.0        40.0         0.0        0.0        0.0   \n",
       "1          0.0        27.0         2.0         0.0        0.0        0.0   \n",
       "2          0.0        95.0         8.0         0.0        0.0        0.0   \n",
       "3          2.0         NaN         NaN         0.0        0.0        0.0   \n",
       "4          0.0       354.0        30.0         0.0        0.0        0.0   \n",
       "\n",
       "   nights_booked gender      shop_am  shop_use  retired  gold_status  \\\n",
       "0          209.0      M     0.000000       0.0      0.0          0.0   \n",
       "1            4.0      M     0.000000       0.0      0.0          0.0   \n",
       "2            6.0      M     0.000000       0.0      0.0          0.0   \n",
       "3            4.0      V     0.000000       0.0      0.0          0.0   \n",
       "4            3.0      V  1454.210627       1.0      0.0          0.0   \n",
       "\n",
       "   score1_pos  score1_neg  score2_pos  score2_neg  score3_pos  score3_neg  \\\n",
       "0    0.467768     0.98334         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2         NaN         NaN    0.232375    0.099529         NaN         NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN    0.889793   \n",
       "4         NaN         NaN         NaN         NaN    0.330503    0.766294   \n",
       "\n",
       "   score4_pos  score4_neg  score5_pos  score5_neg  outcome_profit  \\\n",
       "0    0.838147    0.082288         NaN         NaN         1791.66   \n",
       "1         NaN         NaN         NaN    7.955259         1672.78   \n",
       "2         NaN         NaN    0.101955    1.743020         1001.40   \n",
       "3         NaN         NaN         NaN         NaN         1785.59   \n",
       "4    0.490486    0.542445         NaN         NaN         3140.74   \n",
       "\n",
       "   outcome_damage_inc  outcome_damage_amount  \n",
       "0                   0                   0.00  \n",
       "1                   1                 829.66  \n",
       "2                   0                   0.00  \n",
       "3                   0                   0.00  \n",
       "4                   0                   0.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape\n",
    "pd.options.display.max_columns = None\n",
    "data_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f863dd6",
   "metadata": {},
   "source": [
    "In the next part, Describe() will be used. This allows to see some statistical details from each column in pandas (pandas is a tool for the manipulation of data).  This includes the mean, the standard deviation, quartiles, min, max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb81f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income_am</th>\n",
       "      <th>profit_last_am</th>\n",
       "      <th>profit_am</th>\n",
       "      <th>damage_am</th>\n",
       "      <th>damage_inc</th>\n",
       "      <th>crd_lim_rec</th>\n",
       "      <th>credit_use_ic</th>\n",
       "      <th>gluten_ic</th>\n",
       "      <th>lactose_ic</th>\n",
       "      <th>insurance_ic</th>\n",
       "      <th>spa_ic</th>\n",
       "      <th>empl_ic</th>\n",
       "      <th>cab_requests</th>\n",
       "      <th>bar_no</th>\n",
       "      <th>sport_ic</th>\n",
       "      <th>neighbor_income</th>\n",
       "      <th>age</th>\n",
       "      <th>marketing_permit</th>\n",
       "      <th>urban_ic</th>\n",
       "      <th>dining_ic</th>\n",
       "      <th>presidential</th>\n",
       "      <th>client_segment</th>\n",
       "      <th>sect_empl</th>\n",
       "      <th>prev_stay</th>\n",
       "      <th>prev_all_in_stay</th>\n",
       "      <th>divorce</th>\n",
       "      <th>fam_adult_size</th>\n",
       "      <th>children_no</th>\n",
       "      <th>tenure_mts</th>\n",
       "      <th>tenure_yrs</th>\n",
       "      <th>company_ic</th>\n",
       "      <th>claims_no</th>\n",
       "      <th>claims_am</th>\n",
       "      <th>nights_booked</th>\n",
       "      <th>shop_am</th>\n",
       "      <th>shop_use</th>\n",
       "      <th>retired</th>\n",
       "      <th>gold_status</th>\n",
       "      <th>score1_pos</th>\n",
       "      <th>score1_neg</th>\n",
       "      <th>score2_pos</th>\n",
       "      <th>score2_neg</th>\n",
       "      <th>score3_pos</th>\n",
       "      <th>score3_neg</th>\n",
       "      <th>score4_pos</th>\n",
       "      <th>score4_neg</th>\n",
       "      <th>score5_pos</th>\n",
       "      <th>score5_neg</th>\n",
       "      <th>outcome_profit</th>\n",
       "      <th>outcome_damage_inc</th>\n",
       "      <th>outcome_damage_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4954.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4970.000000</td>\n",
       "      <td>4999.000000</td>\n",
       "      <td>4912.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4761.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4912.000000</td>\n",
       "      <td>4912.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4608.000000</td>\n",
       "      <td>4608.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4973.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4912.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>4947.000000</td>\n",
       "      <td>1.225000e+03</td>\n",
       "      <td>1.314000e+03</td>\n",
       "      <td>1.209000e+03</td>\n",
       "      <td>1.304000e+03</td>\n",
       "      <td>1.261000e+03</td>\n",
       "      <td>1.367000e+03</td>\n",
       "      <td>1.223000e+03</td>\n",
       "      <td>1.324000e+03</td>\n",
       "      <td>1.232000e+03</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2281.260158</td>\n",
       "      <td>696.057712</td>\n",
       "      <td>3637.900950</td>\n",
       "      <td>145.952967</td>\n",
       "      <td>0.352335</td>\n",
       "      <td>3298.716394</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0.024661</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.390944</td>\n",
       "      <td>0.401811</td>\n",
       "      <td>0.024205</td>\n",
       "      <td>6.051507</td>\n",
       "      <td>5.646250</td>\n",
       "      <td>0.287043</td>\n",
       "      <td>32778.558916</td>\n",
       "      <td>44.901152</td>\n",
       "      <td>0.495452</td>\n",
       "      <td>0.883970</td>\n",
       "      <td>0.049267</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>1.298565</td>\n",
       "      <td>0.213463</td>\n",
       "      <td>0.889832</td>\n",
       "      <td>0.252678</td>\n",
       "      <td>0.102486</td>\n",
       "      <td>1.960986</td>\n",
       "      <td>0.385082</td>\n",
       "      <td>273.111545</td>\n",
       "      <td>22.780165</td>\n",
       "      <td>0.018597</td>\n",
       "      <td>0.218314</td>\n",
       "      <td>121.078826</td>\n",
       "      <td>28.992521</td>\n",
       "      <td>403.019960</td>\n",
       "      <td>0.151873</td>\n",
       "      <td>0.182131</td>\n",
       "      <td>0.034769</td>\n",
       "      <td>4.997356e-01</td>\n",
       "      <td>5.003663e-01</td>\n",
       "      <td>4.985522e-01</td>\n",
       "      <td>4.967340e-01</td>\n",
       "      <td>4.942801e-01</td>\n",
       "      <td>4.985876e-01</td>\n",
       "      <td>4.962065e-01</td>\n",
       "      <td>5.013962e-01</td>\n",
       "      <td>5.009593e-01</td>\n",
       "      <td>5.192953</td>\n",
       "      <td>1967.310930</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>189.970736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8365.254507</td>\n",
       "      <td>3051.119275</td>\n",
       "      <td>5726.625669</td>\n",
       "      <td>581.068095</td>\n",
       "      <td>0.889449</td>\n",
       "      <td>4549.646039</td>\n",
       "      <td>0.198858</td>\n",
       "      <td>0.155107</td>\n",
       "      <td>0.292134</td>\n",
       "      <td>0.488011</td>\n",
       "      <td>0.490313</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>3.112104</td>\n",
       "      <td>5.052513</td>\n",
       "      <td>0.452427</td>\n",
       "      <td>6858.671948</td>\n",
       "      <td>16.225094</td>\n",
       "      <td>0.500030</td>\n",
       "      <td>0.320293</td>\n",
       "      <td>0.216447</td>\n",
       "      <td>0.065252</td>\n",
       "      <td>0.800831</td>\n",
       "      <td>0.826006</td>\n",
       "      <td>0.313130</td>\n",
       "      <td>0.434592</td>\n",
       "      <td>0.303317</td>\n",
       "      <td>0.805545</td>\n",
       "      <td>0.832933</td>\n",
       "      <td>152.498416</td>\n",
       "      <td>12.719429</td>\n",
       "      <td>0.135111</td>\n",
       "      <td>0.712408</td>\n",
       "      <td>1783.146726</td>\n",
       "      <td>37.480510</td>\n",
       "      <td>1335.935144</td>\n",
       "      <td>0.358934</td>\n",
       "      <td>0.385991</td>\n",
       "      <td>0.183212</td>\n",
       "      <td>2.879255e-01</td>\n",
       "      <td>2.887168e-01</td>\n",
       "      <td>2.877572e-01</td>\n",
       "      <td>2.897994e-01</td>\n",
       "      <td>2.899165e-01</td>\n",
       "      <td>2.877292e-01</td>\n",
       "      <td>2.886538e-01</td>\n",
       "      <td>2.876226e-01</td>\n",
       "      <td>2.901323e-01</td>\n",
       "      <td>3.159868</td>\n",
       "      <td>1371.061266</td>\n",
       "      <td>0.436129</td>\n",
       "      <td>379.005941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-7.871775</td>\n",
       "      <td>10.680000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>229.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1638.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28630.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.520205e-01</td>\n",
       "      <td>2.510338e-01</td>\n",
       "      <td>2.521282e-01</td>\n",
       "      <td>2.454209e-01</td>\n",
       "      <td>2.405574e-01</td>\n",
       "      <td>2.495061e-01</td>\n",
       "      <td>2.474100e-01</td>\n",
       "      <td>2.506703e-01</td>\n",
       "      <td>2.514905e-01</td>\n",
       "      <td>3.124958</td>\n",
       "      <td>1333.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>469.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1889.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31990.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.974162e-01</td>\n",
       "      <td>4.986215e-01</td>\n",
       "      <td>4.987791e-01</td>\n",
       "      <td>4.985832e-01</td>\n",
       "      <td>4.942465e-01</td>\n",
       "      <td>5.016458e-01</td>\n",
       "      <td>4.933486e-01</td>\n",
       "      <td>5.020603e-01</td>\n",
       "      <td>5.029121e-01</td>\n",
       "      <td>5.188006</td>\n",
       "      <td>1721.235000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1688.000000</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>3165.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35924.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>368.250000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.487276e-01</td>\n",
       "      <td>7.516726e-01</td>\n",
       "      <td>7.441403e-01</td>\n",
       "      <td>7.474935e-01</td>\n",
       "      <td>7.449235e-01</td>\n",
       "      <td>7.464826e-01</td>\n",
       "      <td>7.452133e-01</td>\n",
       "      <td>7.493876e-01</td>\n",
       "      <td>7.512817e-01</td>\n",
       "      <td>7.357425</td>\n",
       "      <td>2223.712500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>202.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>360577.000000</td>\n",
       "      <td>150537.000000</td>\n",
       "      <td>100577.000000</td>\n",
       "      <td>14866.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>104984.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>90587.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>12098.364339</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.986510e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.993125e-01</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>14.776319</td>\n",
       "      <td>31529.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3157.240000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           income_am  profit_last_am      profit_am     damage_am  \\\n",
       "count    4947.000000     4947.000000    4947.000000   4954.000000   \n",
       "mean     2281.260158      696.057712    3637.900950    145.952967   \n",
       "std      8365.254507     3051.119275    5726.625669    581.068095   \n",
       "min         0.000000        0.000000       0.000000      0.000000   \n",
       "25%       229.000000        0.000000    1638.000000      0.000000   \n",
       "50%       469.000000       52.000000    1889.000000      0.000000   \n",
       "75%      1688.000000      810.000000    3165.500000      0.000000   \n",
       "max    360577.000000   150537.000000  100577.000000  14866.000000   \n",
       "\n",
       "        damage_inc   crd_lim_rec  credit_use_ic    gluten_ic   lactose_ic  \\\n",
       "count  4947.000000   4947.000000    4947.000000  4947.000000  4947.000000   \n",
       "mean      0.352335   3298.716394       0.041237     0.024661     0.094199   \n",
       "std       0.889449   4549.646039       0.198858     0.155107     0.292134   \n",
       "min       0.000000      0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000      0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000   1500.000000       0.000000     0.000000     0.000000   \n",
       "75%       0.000000   5000.000000       0.000000     0.000000     0.000000   \n",
       "max      10.000000  30000.000000       1.000000     1.000000     1.000000   \n",
       "\n",
       "       insurance_ic       spa_ic      empl_ic  cab_requests       bar_no  \\\n",
       "count   4947.000000  4970.000000  4999.000000   4912.000000  4947.000000   \n",
       "mean       0.390944     0.401811     0.024205      6.051507     5.646250   \n",
       "std        0.488011     0.490313     0.153700      3.112104     5.052513   \n",
       "min        0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "25%        0.000000     0.000000     0.000000      3.000000     2.000000   \n",
       "50%        0.000000     0.000000     0.000000      6.000000     5.000000   \n",
       "75%        1.000000     1.000000     0.000000      9.000000     8.000000   \n",
       "max        1.000000     1.000000     1.000000     16.000000   111.000000   \n",
       "\n",
       "          sport_ic  neighbor_income          age  marketing_permit  \\\n",
       "count  4947.000000      4761.000000  4947.000000       4947.000000   \n",
       "mean      0.287043     32778.558916    44.901152          0.495452   \n",
       "std       0.452427      6858.671948    16.225094          0.500030   \n",
       "min       0.000000         0.000000    16.000000          0.000000   \n",
       "25%       0.000000     28630.000000    31.000000          0.000000   \n",
       "50%       0.000000     31990.000000    45.000000          0.000000   \n",
       "75%       1.000000     35924.000000    57.000000          1.000000   \n",
       "max       1.000000    104984.000000    97.000000          1.000000   \n",
       "\n",
       "          urban_ic    dining_ic  presidential  client_segment    sect_empl  \\\n",
       "count  4947.000000  4912.000000   4912.000000     4947.000000  4947.000000   \n",
       "mean      0.883970     0.049267      0.004275        1.298565     0.213463   \n",
       "std       0.320293     0.216447      0.065252        0.800831     0.826006   \n",
       "min       0.000000     0.000000      0.000000        0.000000     0.000000   \n",
       "25%       1.000000     0.000000      0.000000        1.000000     0.000000   \n",
       "50%       1.000000     0.000000      0.000000        1.000000     0.000000   \n",
       "75%       1.000000     0.000000      0.000000        2.000000     0.000000   \n",
       "max       1.000000     1.000000      1.000000        5.000000     6.000000   \n",
       "\n",
       "         prev_stay  prev_all_in_stay      divorce  fam_adult_size  \\\n",
       "count  4947.000000       4947.000000  4947.000000     4947.000000   \n",
       "mean      0.889832          0.252678     0.102486        1.960986   \n",
       "std       0.313130          0.434592     0.303317        0.805545   \n",
       "min       0.000000          0.000000     0.000000        1.000000   \n",
       "25%       1.000000          0.000000     0.000000        1.000000   \n",
       "50%       1.000000          0.000000     0.000000        2.000000   \n",
       "75%       1.000000          1.000000     0.000000        3.000000   \n",
       "max       1.000000          1.000000     1.000000        4.000000   \n",
       "\n",
       "       children_no   tenure_mts   tenure_yrs   company_ic    claims_no  \\\n",
       "count  4947.000000  4608.000000  4608.000000  4947.000000  4947.000000   \n",
       "mean      0.385082   273.111545    22.780165     0.018597     0.218314   \n",
       "std       0.832933   152.498416    12.719429     0.135111     0.712408   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000   154.000000    13.000000     0.000000     0.000000   \n",
       "50%       0.000000   271.000000    23.000000     0.000000     0.000000   \n",
       "75%       0.000000   368.250000    31.000000     0.000000     0.000000   \n",
       "max       6.000000   679.000000    57.000000     1.000000     9.000000   \n",
       "\n",
       "          claims_am  nights_booked       shop_am     shop_use      retired  \\\n",
       "count   4973.000000    4947.000000   4947.000000  4912.000000  4947.000000   \n",
       "mean     121.078826      28.992521    403.019960     0.151873     0.182131   \n",
       "std     1783.146726      37.480510   1335.935144     0.358934     0.385991   \n",
       "min        0.000000       1.000000      0.000000     0.000000     0.000000   \n",
       "25%        0.000000       4.000000      0.000000     0.000000     0.000000   \n",
       "50%        0.000000      11.000000      0.000000     0.000000     0.000000   \n",
       "75%        0.000000      45.000000      0.000000     0.000000     0.000000   \n",
       "max    90587.000000     375.000000  12098.364339     1.000000     1.000000   \n",
       "\n",
       "       gold_status    score1_pos    score1_neg    score2_pos    score2_neg  \\\n",
       "count  4947.000000  1.225000e+03  1.314000e+03  1.209000e+03  1.304000e+03   \n",
       "mean      0.034769  4.997356e-01  5.003663e-01  4.985522e-01  4.967340e-01   \n",
       "std       0.183212  2.879255e-01  2.887168e-01  2.877572e-01  2.897994e-01   \n",
       "min       0.000000  1.000000e-07  1.000000e-07  1.000000e-07  1.000000e-07   \n",
       "25%       0.000000  2.520205e-01  2.510338e-01  2.521282e-01  2.454209e-01   \n",
       "50%       0.000000  4.974162e-01  4.986215e-01  4.987791e-01  4.985832e-01   \n",
       "75%       0.000000  7.487276e-01  7.516726e-01  7.441403e-01  7.474935e-01   \n",
       "max       1.000000  9.999999e-01  9.999999e-01  9.999999e-01  9.986510e-01   \n",
       "\n",
       "         score3_pos    score3_neg    score4_pos    score4_neg    score5_pos  \\\n",
       "count  1.261000e+03  1.367000e+03  1.223000e+03  1.324000e+03  1.232000e+03   \n",
       "mean   4.942801e-01  4.985876e-01  4.962065e-01  5.013962e-01  5.009593e-01   \n",
       "std    2.899165e-01  2.877292e-01  2.886538e-01  2.876226e-01  2.901323e-01   \n",
       "min    1.000000e-07  1.000000e-07  1.000000e-07  1.000000e-07  1.000000e-07   \n",
       "25%    2.405574e-01  2.495061e-01  2.474100e-01  2.506703e-01  2.514905e-01   \n",
       "50%    4.942465e-01  5.016458e-01  4.933486e-01  5.020603e-01  5.029121e-01   \n",
       "75%    7.449235e-01  7.464826e-01  7.452133e-01  7.493876e-01  7.512817e-01   \n",
       "max    9.999999e-01  9.999999e-01  9.999999e-01  9.993125e-01  9.999999e-01   \n",
       "\n",
       "        score5_neg  outcome_profit  outcome_damage_inc  outcome_damage_amount  \n",
       "count  1493.000000     5000.000000         5000.000000            5000.000000  \n",
       "mean      5.192953     1967.310930            0.255400             189.970736  \n",
       "std       3.159868     1371.061266            0.436129             379.005941  \n",
       "min      -7.871775       10.680000            0.000000               0.000000  \n",
       "25%       3.124958     1333.320000            0.000000               0.000000  \n",
       "50%       5.188006     1721.235000            0.000000               0.000000  \n",
       "75%       7.357425     2223.712500            1.000000             202.612500  \n",
       "max      14.776319    31529.000000            1.000000            3157.240000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff3a35",
   "metadata": {},
   "source": [
    "The next part was done just to see what happened if we deleted the missing values. It was left just for information but it was decided to not just drop missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e3ac07",
   "metadata": {
    "I": null,
    "did": null,
    "do": null,
    "in": null,
    "incorrectly_encoded_metadata": "variable.==>",
    "not": null,
    "that": null,
    "things": null,
    "this": null,
    "title": "Visualizing the missing data, percent is the percentage of  of null data by each",
    "way": null
   },
   "outputs": [],
   "source": [
    "# total = data_train.isnull().sum().sort_values(ascending=False)\n",
    "# percent = (data_train.isnull().sum()/data_train.isnull().count()).sort_values(ascending=False)\n",
    "# (data_train.isnull().sum(axis=1))[data_train.isnull().sum(axis=1) > 30]\n",
    "# table\n",
    "# missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "# print(missing_data.head(30))\n",
    "# print(data_train['score2_pos'].value_counts())\n",
    "# data_train = data_train.drop((missing_data[missing_data['Percent'] > 0.30]).index,1)\n",
    "# data_train.dropna(inplace=True) \n",
    "#we could drop all that is NaN, but we will loose observations. (4425, 43) instead of (4425, 43) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34da802c",
   "metadata": {},
   "source": [
    "After this, the preprocessing will actually start. But first, it is important to understand that what is done in the training data set, has to also be done also in the score data set. For this, both data set will be fused, but the outcomes need to be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b2c7938",
   "metadata": {
    "title": "Remove outcomes, because we will work on the missing data, and we can use the train and the test set for this (what is done in one, it has to be done in the other one), but we have to remove the outcome"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['income_am', 'profit_last_am', 'profit_am', 'damage_am', 'damage_inc',\n",
      "       'crd_lim_rec', 'credit_use_ic', 'gluten_ic', 'lactose_ic',\n",
      "       'insurance_ic', 'spa_ic', 'empl_ic', 'cab_requests', 'married_cd',\n",
      "       'bar_no', 'sport_ic', 'neighbor_income', 'age', 'marketing_permit',\n",
      "       'urban_ic', 'dining_ic', 'presidential', 'client_segment', 'sect_empl',\n",
      "       'prev_stay', 'prev_all_in_stay', 'divorce', 'fam_adult_size',\n",
      "       'children_no', 'tenure_mts', 'tenure_yrs', 'company_ic', 'claims_no',\n",
      "       'claims_am', 'nights_booked', 'gender', 'shop_am', 'shop_use',\n",
      "       'retired', 'gold_status', 'score1_pos', 'score1_neg', 'score2_pos',\n",
      "       'score2_neg', 'score3_pos', 'score3_neg', 'score4_pos', 'score4_neg',\n",
      "       'score5_pos', 'score5_neg', 'outcome_profit', 'outcome_damage_inc',\n",
      "       'outcome_damage_amount'],\n",
      "      dtype='object')\n",
      "(5000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.columns)\n",
    "data_feat = data_train.drop(['outcome_profit', 'outcome_damage_inc', 'outcome_damage_amount'], axis=1)\n",
    "print(data_feat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cf4e47",
   "metadata": {},
   "source": [
    "Then categorical features were chosen. In the next part, the different values of each of them are counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5e048eb",
   "metadata": {
    "title": "fuse the score and the training datasets"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 50)\n",
      "(5500, 50)\n",
      "1.0    3712\n",
      "2.0     925\n",
      "0.0     352\n",
      "3.0     329\n",
      "4.0      87\n",
      "5.0      38\n",
      "Name: client_segment, dtype: int64\n",
      "0.0    4820\n",
      "1.0     468\n",
      "6.0      78\n",
      "2.0      45\n",
      "4.0      29\n",
      "3.0       3\n",
      "Name: sect_empl, dtype: int64\n",
      "M    2734\n",
      "V    2709\n",
      "Name: gender, dtype: int64\n",
      "0.0    4456\n",
      "1.0     987\n",
      "Name: retired, dtype: int64\n",
      "0.0    5241\n",
      "1.0     202\n",
      "Name: gold_status, dtype: int64\n",
      "1.0    4848\n",
      "0.0     595\n",
      "Name: prev_stay, dtype: int64\n",
      "0.0    4884\n",
      "1.0     559\n",
      "Name: divorce, dtype: int64\n",
      "True     4460\n",
      "False    1040\n",
      "Name: married_cd, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(score.shape)\n",
    "datafull = pd.concat([data_feat, score])\n",
    "print(datafull.shape)\n",
    "print(datafull['client_segment'].value_counts())\n",
    "print(datafull['sect_empl'].value_counts())\n",
    "print(datafull['gender'].value_counts())\n",
    "print(datafull['retired'].value_counts())\n",
    "print(datafull['gold_status'].value_counts())\n",
    "print(datafull['prev_stay'].value_counts())\n",
    "print(datafull['divorce'].value_counts())\n",
    "print(datafull['married_cd'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1328f383",
   "metadata": {},
   "source": [
    "For the variables, a mode imputation was done instead of making a separate missing category. A disadvantage is that the most frequent value will be favored. But every technique, has its downfalls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73392068",
   "metadata": {
    "title": "Mode imputer instead of separate categories"
   },
   "outputs": [],
   "source": [
    "# datafull['client_segment'] = pd.Categorical(datafull['client_segment'])\n",
    "# datafull['sect_empl'] = pd.Categorical(datafull['sect_empl'])\n",
    "# datafull['retired'] = pd.Categorical(datafull['retired'])\n",
    "# datafull['gold_status'] = pd.Categorical(datafull['gold_status'])\n",
    "# datafull['prev_stay'] = pd.Categorical(datafull['prev_stay'])\n",
    "# datafull['divorce'] = pd.Categorical(datafull['divorce'])\n",
    "\n",
    "impute_mode = SimpleImputer (strategy='most_frequent')\n",
    "for cols in ['client_segment', \"credit_use_ic\", \"gluten_ic\", \"lactose_ic\",\"insurance_ic\",\"marketing_permit\", \"presidential\", \"urban_ic\", \"prev_all_in_stay\", \"shop_use\", \n",
    "             \"company_ic\", \"dining_ic\", \"spa_ic\",\"sport_ic\",\"empl_ic\",'sect_empl', \"retired\", \"gold_status\", \"prev_stay\", 'divorce', \"gender\"]:  \n",
    "      datafull[cols] = impute_mode.fit_transform(datafull[[cols]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07f2636",
   "metadata": {},
   "source": [
    "The categorical features that had values different from 0 and 1, were dummified (separated in categories) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "270d844e",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Dummify them! (the ones that are not 0 and 1... Gender, sect_empl and client_segment)"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5500, 50)\n",
      "(5500, 64)\n",
      "     income_am  profit_last_am  profit_am  damage_am  damage_inc  crd_lim_rec  \\\n",
      "0        227.0             0.0     3201.0      888.0         6.0      15000.0   \n",
      "1        268.0            16.0     1682.0        0.0         0.0        750.0   \n",
      "2        283.0            23.0     1673.0        0.0         0.0        750.0   \n",
      "3        227.0             0.0     1685.0        0.0         0.0          0.0   \n",
      "4       4091.0          1028.0     3425.0      785.0         2.0      14000.0   \n",
      "..         ...             ...        ...        ...         ...          ...   \n",
      "995     3103.0             0.0     9466.0     1206.0         2.0      12500.0   \n",
      "996        NaN             NaN        NaN        NaN         NaN          NaN   \n",
      "997      250.0           823.0     1646.0        0.0         0.0       1500.0   \n",
      "998     6382.0           561.0     7265.0        0.0         0.0       1500.0   \n",
      "999     5556.0          2464.0     2464.0        0.0         0.0          0.0   \n",
      "\n",
      "     credit_use_ic  gluten_ic  lactose_ic  insurance_ic  spa_ic  empl_ic  \\\n",
      "0              0.0        0.0         0.0           0.0     1.0      0.0   \n",
      "1              0.0        0.0         0.0           1.0     1.0      0.0   \n",
      "2              0.0        0.0         0.0           1.0     0.0      0.0   \n",
      "3              0.0        0.0         0.0           0.0     0.0      0.0   \n",
      "4              0.0        0.0         1.0           0.0     1.0      0.0   \n",
      "..             ...        ...         ...           ...     ...      ...   \n",
      "995            1.0        1.0         1.0           1.0     1.0      0.0   \n",
      "996            0.0        0.0         0.0           0.0     0.0      0.0   \n",
      "997            0.0        0.0         0.0           1.0     1.0      0.0   \n",
      "998            0.0        0.0         0.0           0.0     0.0      0.0   \n",
      "999            0.0        0.0         0.0           0.0     0.0      0.0   \n",
      "\n",
      "     cab_requests  married_cd  bar_no  sport_ic  neighbor_income   age  \\\n",
      "0             3.0        True     2.0       1.0          28936.0  37.0   \n",
      "1             7.0        True     3.0       0.0          16674.0  18.0   \n",
      "2             1.0        True     4.0       0.0          32552.0  21.0   \n",
      "3             6.0        True     8.0       1.0          32252.0  37.0   \n",
      "4             4.0       False     2.0       1.0          29605.0  26.0   \n",
      "..            ...         ...     ...       ...              ...   ...   \n",
      "995           5.0        True    12.0       1.0          32920.0  46.0   \n",
      "996           NaN       False     NaN       0.0              NaN   NaN   \n",
      "997           7.0        True     5.0       0.0          29285.0  37.0   \n",
      "998           1.0        True     2.0       0.0          42836.0  56.0   \n",
      "999           4.0        True     4.0       0.0          35505.0  64.0   \n",
      "\n",
      "     marketing_permit  urban_ic  dining_ic  presidential client_segment  \\\n",
      "0                 0.0       1.0        0.0           0.0            1.0   \n",
      "1                 0.0       0.0        0.0           0.0            1.0   \n",
      "2                 0.0       1.0        0.0           0.0            1.0   \n",
      "3                 0.0       1.0        0.0           0.0            1.0   \n",
      "4                 0.0       1.0        0.0           0.0            2.0   \n",
      "..                ...       ...        ...           ...            ...   \n",
      "995               0.0       1.0        0.0           0.0            2.0   \n",
      "996               0.0       1.0        0.0           0.0            1.0   \n",
      "997               1.0       1.0        0.0           0.0            1.0   \n",
      "998               0.0       1.0        0.0           0.0            2.0   \n",
      "999               0.0       1.0        0.0           0.0            2.0   \n",
      "\n",
      "    sect_empl  prev_stay  prev_all_in_stay  divorce  fam_adult_size  \\\n",
      "0         1.0        1.0               1.0      0.0             3.0   \n",
      "1         0.0        0.0               0.0      0.0             1.0   \n",
      "2         0.0        1.0               0.0      0.0             1.0   \n",
      "3         0.0        1.0               0.0      0.0             3.0   \n",
      "4         0.0        1.0               0.0      0.0             2.0   \n",
      "..        ...        ...               ...      ...             ...   \n",
      "995       0.0        1.0               1.0      0.0             3.0   \n",
      "996       0.0        1.0               0.0      0.0             NaN   \n",
      "997       0.0        1.0               0.0      0.0             3.0   \n",
      "998       0.0        0.0               0.0      0.0             3.0   \n",
      "999       0.0        1.0               0.0      0.0             1.0   \n",
      "\n",
      "     children_no  tenure_mts  tenure_yrs  company_ic  claims_no  claims_am  \\\n",
      "0            2.0       476.0        40.0         0.0        0.0        0.0   \n",
      "1            0.0        27.0         2.0         0.0        0.0        0.0   \n",
      "2            0.0        95.0         8.0         0.0        0.0        0.0   \n",
      "3            2.0         NaN         NaN         0.0        0.0        0.0   \n",
      "4            0.0       354.0        30.0         0.0        0.0        0.0   \n",
      "..           ...         ...         ...         ...        ...        ...   \n",
      "995          2.0       314.0        26.0         0.0        1.0        0.0   \n",
      "996          NaN         NaN         NaN         0.0        NaN        NaN   \n",
      "997          0.0        26.0         2.0         0.0        0.0        0.0   \n",
      "998          0.0       361.0        30.0         0.0        1.0        0.0   \n",
      "999          0.0       209.0        17.0         0.0        0.0        0.0   \n",
      "\n",
      "     nights_booked gender      shop_am  shop_use  retired  gold_status  \\\n",
      "0            209.0      M     0.000000       0.0      0.0          0.0   \n",
      "1              4.0      M     0.000000       0.0      0.0          0.0   \n",
      "2              6.0      M     0.000000       0.0      0.0          0.0   \n",
      "3              4.0      V     0.000000       0.0      0.0          0.0   \n",
      "4              3.0      V  1454.210627       1.0      0.0          0.0   \n",
      "..             ...    ...          ...       ...      ...          ...   \n",
      "995          158.0      M   475.946777       1.0      0.0          1.0   \n",
      "996            NaN      M          NaN       0.0      0.0          0.0   \n",
      "997           11.0      V     0.000000       0.0      0.0          0.0   \n",
      "998           22.0      V     0.000000       0.0      0.0          0.0   \n",
      "999            4.0      V     0.000000       0.0      1.0          0.0   \n",
      "\n",
      "     score1_pos  score1_neg  score2_pos  score2_neg  score3_pos  score3_neg  \\\n",
      "0      0.467768    0.983340         NaN         NaN         NaN         NaN   \n",
      "1           NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2           NaN         NaN    0.232375    0.099529         NaN         NaN   \n",
      "3           NaN         NaN         NaN         NaN         NaN    0.889793   \n",
      "4           NaN         NaN         NaN         NaN    0.330503    0.766294   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "995    0.581640    0.293551         NaN         NaN         NaN         NaN   \n",
      "996         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "997    0.074012    0.742951    0.914448    0.459659         NaN         NaN   \n",
      "998         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "999    0.450102    0.724313    0.481430    0.201374         NaN         NaN   \n",
      "\n",
      "     score4_pos  score4_neg  score5_pos  score5_neg  gender_M  gender_V  \\\n",
      "0      0.838147    0.082288         NaN         NaN         1         0   \n",
      "1           NaN         NaN         NaN    7.955259         1         0   \n",
      "2           NaN         NaN    0.101955    1.743020         1         0   \n",
      "3           NaN         NaN         NaN         NaN         0         1   \n",
      "4      0.490486    0.542445         NaN         NaN         0         1   \n",
      "..          ...         ...         ...         ...       ...       ...   \n",
      "995         NaN         NaN         NaN         NaN         1         0   \n",
      "996         NaN         NaN         NaN         NaN         1         0   \n",
      "997         NaN         NaN         NaN         NaN         0         1   \n",
      "998         NaN         NaN         NaN         NaN         0         1   \n",
      "999         NaN         NaN    0.648959    1.811479         0         1   \n",
      "\n",
      "     client_segment_0.0  client_segment_1.0  client_segment_2.0  \\\n",
      "0                     0                   1                   0   \n",
      "1                     0                   1                   0   \n",
      "2                     0                   1                   0   \n",
      "3                     0                   1                   0   \n",
      "4                     0                   0                   1   \n",
      "..                  ...                 ...                 ...   \n",
      "995                   0                   0                   1   \n",
      "996                   0                   1                   0   \n",
      "997                   0                   1                   0   \n",
      "998                   0                   0                   1   \n",
      "999                   0                   0                   1   \n",
      "\n",
      "     client_segment_3.0  client_segment_4.0  client_segment_5.0  \\\n",
      "0                     0                   0                   0   \n",
      "1                     0                   0                   0   \n",
      "2                     0                   0                   0   \n",
      "3                     0                   0                   0   \n",
      "4                     0                   0                   0   \n",
      "..                  ...                 ...                 ...   \n",
      "995                   0                   0                   0   \n",
      "996                   0                   0                   0   \n",
      "997                   0                   0                   0   \n",
      "998                   0                   0                   0   \n",
      "999                   0                   0                   0   \n",
      "\n",
      "     sect_empl_0.0  sect_empl_1.0  sect_empl_2.0  sect_empl_3.0  \\\n",
      "0                0              1              0              0   \n",
      "1                1              0              0              0   \n",
      "2                1              0              0              0   \n",
      "3                1              0              0              0   \n",
      "4                1              0              0              0   \n",
      "..             ...            ...            ...            ...   \n",
      "995              1              0              0              0   \n",
      "996              1              0              0              0   \n",
      "997              1              0              0              0   \n",
      "998              1              0              0              0   \n",
      "999              1              0              0              0   \n",
      "\n",
      "     sect_empl_4.0  sect_empl_6.0  \n",
      "0                0              0  \n",
      "1                0              0  \n",
      "2                0              0  \n",
      "3                0              0  \n",
      "4                0              0  \n",
      "..             ...            ...  \n",
      "995              0              0  \n",
      "996              0              0  \n",
      "997              0              0  \n",
      "998              0              0  \n",
      "999              0              0  \n",
      "\n",
      "[1000 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "datafull['client_segment'] = pd.Categorical(datafull['client_segment'])\n",
    "datafull['sect_empl'] = pd.Categorical(datafull['sect_empl'])\n",
    "# The NaN categorie won't be necessary anymore, thanks to the mode imputing.\n",
    "pd.get_dummies(datafull[['client_segment', 'sect_empl']], dummy_na=False).head()\n",
    "print(datafull.shape)\n",
    "datafull2 = pd.concat([datafull,pd.get_dummies(datafull[['gender','client_segment', 'sect_empl']], dummy_na=False)], axis=1)\n",
    "print(datafull2.shape)\n",
    "print(datafull2.head(1000))     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c340877",
   "metadata": {},
   "source": [
    "After creating the dummies for the necessary variables, the original features and 1 dummy category was dropped in each of them. Also a new  feature, \"profit per night\" was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcb8d688",
   "metadata": {
    "title": "Dropping the original features is necessary, and I will also drop one dummy from the categorical data that I had to create \"extra columns\" for."
   },
   "outputs": [],
   "source": [
    "datafull2.drop(['client_segment', 'sect_empl', 'gender', 'client_segment_5.0','sect_empl_6.0','gender_V'], axis=1, inplace=True)\n",
    "datafull2.shape\n",
    "\n",
    "datafull2['profitpernight'] = datafull2['profit_am'] / datafull2['nights_booked']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d26547",
   "metadata": {},
   "source": [
    "Now the data with over 25% missing values will be found. Most of it consist in the features related to scores. The solution dropped them, but we decided to try another option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7080e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score1_pos    0.755091\n",
       "score1_neg    0.736727\n",
       "score2_pos    0.760000\n",
       "score2_neg    0.740364\n",
       "score3_pos    0.746000\n",
       "score3_neg    0.725091\n",
       "score4_pos    0.756000\n",
       "score4_neg    0.736364\n",
       "score5_pos    0.752000\n",
       "score5_neg    0.700545\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(datafull2.isnull().mean())[datafull2.isnull().mean() > 0.25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17c0339",
   "metadata": {},
   "source": [
    "Something important that was mentioned during class was that sometimes it is not worthy to use very complex methods like soft imputing to avoid dropping features with missing values. So we decided to try something simple: a mean imputing. The scores are quantitative, and of course, a downside of this is that it could bring us distortion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f82cb67",
   "metadata": {
    "title": "Missing values per column. I decided to not drop them and use a mean imput instead."
   },
   "outputs": [],
   "source": [
    "impute_quant = SimpleImputer (strategy='mean')\n",
    "for cols in ['score1_pos', 'score1_neg', 'score2_pos', 'score2_neg', 'score3_pos',\n",
    "       'score3_neg', 'score4_pos', 'score4_neg', 'score5_pos', 'score5_neg']:  # Missing data, Scores are quantitative\n",
    "      datafull2[cols] = impute_quant.fit_transform(datafull2[[cols]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6da68c",
   "metadata": {},
   "source": [
    "Then the missing values per row were dropped (observations). But there were not observations with this percentage of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dd57ae1",
   "metadata": {
    "title": "No we are looking for the Missing values per row"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5500, 59)\n",
      "(5500, 59)\n"
     ]
    }
   ],
   "source": [
    "print(datafull2.shape)\n",
    "datafull2.dropna(thresh = datafull2.shape[1]*0.25, axis = 0, inplace = True)\n",
    "print(datafull2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2256989b",
   "metadata": {},
   "source": [
    "After this, a mean imputation was done for the other missing values that could be present (here the binary data was already treated before). And at the end there was not more missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a86e5444",
   "metadata": {
    "title": "Imputation using the mean for the other missing values"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2033\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(datafull2.isnull().sum().sum())\n",
    "datafull2.fillna(datafull2.mean(), inplace=True)\n",
    "print(datafull2.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d7d103",
   "metadata": {},
   "source": [
    "In the next section, the features will be rescaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ffc9f4a",
   "metadata": {
    "title": "Time to the rescale"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "datafull3 = pd.DataFrame(scaler.fit_transform(datafull2))\n",
    "datafull3.columns = datafull2.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c5cddf",
   "metadata": {},
   "source": [
    "Then, the score and the train datasets will be separated and the outcome features will be reinstated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6377f14",
   "metadata": {
    "title": "Now the test and the train sets should be separated again (they were together just for the preprocessing so that what we do for one, we do for the other one)"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 62)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 59)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.concat([data_train[['outcome_profit', 'outcome_damage_inc', 'outcome_damage_amount']],datafull3[0:5000]], axis=1)\n",
    "print(data_train.shape)\n",
    "score = datafull3[5000:5500] #The score dataset will be the last 500 observations\n",
    "score.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4cc667",
   "metadata": {},
   "source": [
    "## 2. Profit Model using GAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611a1eaa",
   "metadata": {},
   "source": [
    "After the preprocessing, the data was split in train and test. The test size was decided to be 20%, so that more data was available for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c97e3e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 62)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_train.drop(['outcome_profit', 'outcome_damage_inc', 'outcome_damage_amount'],1),\n",
    "                                                    data_train['outcome_profit'], test_size=0.2, random_state=48)\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d80aef3",
   "metadata": {},
   "source": [
    "We astart working with splines, to set a baseline quality. In this case instead of using the most important features, we decided to use all the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "777b09a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAM(callbacks=['deviance', 'diffs'], distribution='normal', \n",
       "   fit_intercept=True, link='identity', max_iter=100, \n",
       "   terms=s(0) + s(1) + s(2) + s(3) + s(4) + s(5) + s(6) + s(7) + s(8) + s(9) + s(10) + s(11) + s(12) + s(13) + s(14) + s(15) + s(16) + s(17) + s(18) + s(19) + s(20) + s(21) + s(22) + s(23) + s(24) + s(25) + s(26) + s(27) + s(28) + s(29) + s(30) + s(31) + s(32) + s(33) + s(34) + s(35) + s(36) + s(37) + s(38) + s(39) + s(40) + s(41) + s(42) + s(43) + s(44) + s(45) + s(46) + s(47) + s(48) + s(49) + s(50) + s(51) + s(52) + s(53) + s(54) + s(55) + s(56) + s(57) + s(58),\n",
       "   tol=0.0001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pygam import GAM, s, te\n",
    "\n",
    "GAM(s(0, n_splines=200) + s(1, n_splines=200) + s(2, n_splines=200) + s(3, n_splines=200) + s(4, n_splines=200) + \n",
    "    s(5, n_splines=200) + s(6, n_splines=200) + s(7, n_splines=200) + s(8, n_splines=200) + s(9, n_splines=200) + \n",
    "    s(10, n_splines=200) + s(11, n_splines=200) + s(12, n_splines=200) + s(13, n_splines=200) + s(14, n_splines=200) + \n",
    "    s(15, n_splines=200) + s(16, n_splines=200) + s(17, n_splines=200) + s(18, n_splines=200) + s(19, n_splines=200) + \n",
    "    s(20, n_splines=200) + s(21, n_splines=200) + s(22, n_splines=200) + s(23, n_splines=200) + s(24, n_splines=200) + \n",
    "    s(25, n_splines=200) + s(26, n_splines=200) + s(27, n_splines=200) + s(28, n_splines=200) + s(29, n_splines=200) + \n",
    "    s(30, n_splines=200) + s(31, n_splines=200) + s(32, n_splines=200) + s(33, n_splines=200) + s(34, n_splines=200) + \n",
    "    s(35, n_splines=200) + s(36, n_splines=200) + s(37, n_splines=200) + s(38, n_splines=200) + s(39, n_splines=200) + \n",
    "    s(40, n_splines=200) + s(41, n_splines=200) + s(42, n_splines=200) + s(43, n_splines=200) + s(44, n_splines=200) + \n",
    "    s(45, n_splines=200) + s(46, n_splines=200) + s(47, n_splines=200) + s(48, n_splines=200) + s(49, n_splines=200) + \n",
    "    s(50, n_splines=200) + s(51, n_splines=200) + s(52, n_splines=200) + s(53, n_splines=200) + s(54, n_splines=200) + \n",
    "    s(55, n_splines=200) + s(56, n_splines=200) + s(57, n_splines=200) + s(58, n_splines=200)\n",
    "    , distribution='normal', link='identity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa501c7",
   "metadata": {},
   "source": [
    "In the next section, the model is fitted and because we are in the simplest setting, we can also use LinearGAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "948e2d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearGAM(callbacks=[Deviance(), Diffs()], fit_intercept=True, \n",
       "   max_iter=100, scale=None, \n",
       "   terms=s(0) + s(1) + s(2) + s(3) + s(4) + s(5) + s(6) + s(7) + s(8) + s(9) + s(10) + s(11) + s(12) + s(13) + s(14) + s(15) + s(16) + s(17) + s(18) + s(19) + s(20) + s(21) + s(22) + s(23) + s(24) + s(25) + s(26) + s(27) + s(28) + s(29) + s(30) + s(31) + s(32) + s(33) + s(34) + s(35) + s(36) + s(37) + s(38) + s(39) + s(40) + s(41) + s(42) + s(43) + s(44) + s(45) + s(46) + s(47) + s(48) + s(49) + s(50) + s(51) + s(52) + s(53) + s(54) + s(55) + s(56) + s(57) + s(58) + intercept,\n",
       "   tol=0.0001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pygam import LinearGAM, s\n",
    "\n",
    "## model\n",
    "gam = LinearGAM(s(0, n_splines=200) + s(1, n_splines=200) + s(2, n_splines=200) + s(3, n_splines=200) + s(4, n_splines=200) + \n",
    "    s(5, n_splines=200) + s(6, n_splines=200) + s(7, n_splines=200) + s(8, n_splines=200) + s(9, n_splines=200) +    \n",
    "    s(10, n_splines=200) + s(11, n_splines=200) + s(12, n_splines=200) + s(13, n_splines=200) + s(14, n_splines=200) + \n",
    "    s(15, n_splines=200) + s(16, n_splines=200) + s(17, n_splines=200) + s(18, n_splines=200) + s(19, n_splines=200) + \n",
    "    s(20, n_splines=200) + s(21, n_splines=200) + s(22, n_splines=200) + s(23, n_splines=200) + s(24, n_splines=200) + \n",
    "    s(25, n_splines=200) + s(26, n_splines=200) + s(27, n_splines=200) + s(28, n_splines=200) + s(29, n_splines=200) + \n",
    "    s(30, n_splines=200) + s(31, n_splines=200) + s(32, n_splines=200) + s(33, n_splines=200) + s(34, n_splines=200) + \n",
    "    s(35, n_splines=200) + s(36, n_splines=200) + s(37, n_splines=200) + s(38, n_splines=200) + s(39, n_splines=200) + \n",
    "    s(40, n_splines=200) + s(41, n_splines=200) + s(42, n_splines=200) + s(43, n_splines=200) + s(44, n_splines=200) + \n",
    "    s(45, n_splines=200) + s(46, n_splines=200) + s(47, n_splines=200) + s(48, n_splines=200) + s(49, n_splines=200) + \n",
    "    s(50, n_splines=200) + s(51, n_splines=200) + s(52, n_splines=200) + s(53, n_splines=200) + s(54, n_splines=200) + \n",
    "    s(55, n_splines=200) + s(56, n_splines=200) + s(57, n_splines=200) + s(58, n_splines=200))\n",
    "gam.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "704ea020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearGAM                                                                                                 \n",
      "=============================================== ==========================================================\n",
      "Distribution:                        NormalDist Effective DoF:                                    678.5999\n",
      "Link Function:                     IdentityLink Log Likelihood:                                 -57459.876\n",
      "Number of Samples:                         4000 AIC:                                           116278.9518\n",
      "                                                AICc:                                          116557.6381\n",
      "                                                GCV:                                           987027.8982\n",
      "                                                Scale:                                         691093.1355\n",
      "                                                Pseudo R-Squared:                                   0.7008\n",
      "==========================================================================================================\n",
      "Feature Function                  Lambda               Rank         EDoF         P > x        Sig. Code   \n",
      "================================= ==================== ============ ============ ============ ============\n",
      "s(0)                              [0.6]                200                       1.11e-16     ***         \n",
      "s(1)                              [0.6]                200                       1.11e-16     ***         \n",
      "s(2)                              [0.6]                200                       1.11e-16     ***         \n",
      "s(3)                              [0.6]                200                       1.11e-16     ***         \n",
      "s(4)                              [0.6]                200                       1.11e-16     ***         \n",
      "s(5)                              [0.6]                200                       1.11e-16     ***         \n",
      "s(6)                              [0.6]                200                       1.11e-16     ***         \n",
      "s(7)                              [0.6]                200                       1.11e-16     ***         \n",
      "s(8)                              [0.6]                200                       1.11e-16     ***         \n",
      "s(9)                              [0.6]                200                       1.11e-16     ***         \n",
      "s(10)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(11)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(12)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(13)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(14)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(15)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(16)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(17)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(18)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(19)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(20)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(21)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(22)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(23)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(24)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(25)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(26)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(27)                             [0.6]                200                       3.86e-14     ***         \n",
      "s(28)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(29)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(30)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(31)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(32)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(33)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(34)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(35)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(36)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(37)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(38)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(39)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(40)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(41)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(42)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(43)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(44)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(45)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(46)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(47)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(48)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(49)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(50)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(51)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(52)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(53)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(54)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(55)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(56)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(57)                             [0.6]                200                       1.11e-16     ***         \n",
      "s(58)                             [0.6]                200                       1.11e-16     ***         \n",
      "intercept                                              1                         1.11e-16     ***         \n",
      "==========================================================================================================\n",
      "Significance codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
      "\n",
      "WARNING: Fitting splines and a linear function to a feature introduces a model identifiability problem\n",
      "         which can cause p-values to appear significant when they are not.\n",
      "\n",
      "WARNING: p-values calculated in this manner behave correctly for un-penalized models or models with\n",
      "         known smoothing parameters, but when smoothing parameters have been estimated, the p-values\n",
      "         are typically lower than they should be, meaning that the tests reject the null too readily.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-dec6a6acdaaa>:1: UserWarning: KNOWN BUG: p-values computed in this summary are likely much smaller than they should be. \n",
      " \n",
      "Please do not make inferences based on these values! \n",
      "\n",
      "Collaborate on a solution, and stay up to date at: \n",
      "github.com/dswah/pyGAM/issues/163 \n",
      "\n",
      "  gam.summary()\n"
     ]
    }
   ],
   "source": [
    "gam.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848599bd",
   "metadata": {},
   "source": [
    "Now crossvalidation has to be done to optimaze the penalization. For this, a grid search is carried out. In this point, the algorithm does not converge. But I will continue the next steps that were planned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0167a569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18% (2 of 11) |####                     | Elapsed Time: 0:40:52 ETA:   3:53:27C:\\Users\\mhinojosalee\\Anaconda3\\lib\\site-packages\\pygam\\pygam.py:752: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  np.fill_diagonal(Dinv, d**-1) # invert the singular values\n",
      "C:\\Users\\mhinojosalee\\Anaconda3\\lib\\site-packages\\pygam\\pygam.py:752: RuntimeWarning: overflow encountered in reciprocal\n",
      "  np.fill_diagonal(Dinv, d**-1) # invert the singular values\n",
      " 27% (3 of 11) |######                   | Elapsed Time: 1:22:45 ETA:   5:35:03C:\\Users\\mhinojosalee\\Anaconda3\\lib\\site-packages\\pygam\\pygam.py:752: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  np.fill_diagonal(Dinv, d**-1) # invert the singular values\n",
      "C:\\Users\\mhinojosalee\\Anaconda3\\lib\\site-packages\\pygam\\pygam.py:752: RuntimeWarning: overflow encountered in reciprocal\n",
      "  np.fill_diagonal(Dinv, d**-1) # invert the singular values\n",
      " 36% (4 of 11) |#########                | Elapsed Time: 2:04:40 ETA:   4:53:31C:\\Users\\mhinojosalee\\Anaconda3\\lib\\site-packages\\pygam\\pygam.py:752: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  np.fill_diagonal(Dinv, d**-1) # invert the singular values\n",
      "C:\\Users\\mhinojosalee\\Anaconda3\\lib\\site-packages\\pygam\\pygam.py:752: RuntimeWarning: overflow encountered in reciprocal\n",
      "  np.fill_diagonal(Dinv, d**-1) # invert the singular values\n",
      " 45% (5 of 11) |###########              | Elapsed Time: 2:44:04 ETA:   3:56:19C:\\Users\\mhinojosalee\\Anaconda3\\lib\\site-packages\\pygam\\pygam.py:752: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  np.fill_diagonal(Dinv, d**-1) # invert the singular values\n",
      "C:\\Users\\mhinojosalee\\Anaconda3\\lib\\site-packages\\pygam\\pygam.py:752: RuntimeWarning: overflow encountered in reciprocal\n",
      "  np.fill_diagonal(Dinv, d**-1) # invert the singular values\n",
      " 54% (6 of 11) |#############            | Elapsed Time: 3:25:01 ETA:   3:24:44C:\\Users\\mhinojosalee\\Anaconda3\\lib\\site-packages\\pygam\\pygam.py:752: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  np.fill_diagonal(Dinv, d**-1) # invert the singular values\n",
      "C:\\Users\\mhinojosalee\\Anaconda3\\lib\\site-packages\\pygam\\pygam.py:752: RuntimeWarning: overflow encountered in reciprocal\n",
      "  np.fill_diagonal(Dinv, d**-1) # invert the singular values\n",
      " 63% (7 of 11) |###############          | Elapsed Time: 4:06:23 ETA:   2:45:28"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2e6554b9692a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m51\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m52\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m53\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m54\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     s(55, n_splines=200) + s(56, n_splines=200) + s(57, n_splines=200) + s(58, n_splines=200))\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mgam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgridsearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pygam\\pygam.py\u001b[0m in \u001b[0;36mgridsearch\u001b[1;34m(self, X, y, weights, return_scores, keep_best, objective, progress, **param_grids)\u001b[0m\n\u001b[0;32m   1892\u001b[0m                     \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m                     \u001b[0mgam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1894\u001b[1;33m                 \u001b[0mgam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pygam\\pygam.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, weights)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m         \u001b[1;31m# optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pirls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m         \u001b[1;31m# if self._opt == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m         \u001b[1;31m#     self._pirls(X, y, weights)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pygam\\pygam.py\u001b[0m in \u001b[0;36m_pirls\u001b[1;34m(self, X, Y, weights)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[1;31m# SVD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m             \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    750\u001b[0m             \u001b[0msvd_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# mask out small singular values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msvd\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m         \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->DdD'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->ddd'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1660\u001b[1;33m         \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1661\u001b[0m         \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1662\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_svd_nonconvergence\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_svd_nonconvergence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SVD did not converge\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_lstsq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: SVD did not converge"
     ]
    }
   ],
   "source": [
    "from pygam import LinearGAM, s\n",
    "\n",
    "## model\n",
    "gam = LinearGAM(s(0, n_splines=200) + s(1, n_splines=200) + s(2, n_splines=200) + s(3, n_splines=200) + s(4, n_splines=200) + \n",
    "    s(5, n_splines=200) + s(6, n_splines=200) + s(7, n_splines=200) + s(8, n_splines=200) + s(9, n_splines=200) +     \n",
    "    s(10, n_splines=200) + s(11, n_splines=200) + s(12, n_splines=200) + s(13, n_splines=200) + s(14, n_splines=200) + \n",
    "    s(15, n_splines=200) + s(16, n_splines=200) + s(17, n_splines=200) + s(18, n_splines=200) + s(19, n_splines=200) + \n",
    "    s(20, n_splines=200) + s(21, n_splines=200) + s(22, n_splines=200) + s(23, n_splines=200) + s(24, n_splines=200) + \n",
    "    s(25, n_splines=200) + s(26, n_splines=200) + s(27, n_splines=200) + s(28, n_splines=200) + s(29, n_splines=200) + \n",
    "    s(30, n_splines=200) + s(31, n_splines=200) + s(32, n_splines=200) + s(33, n_splines=200) + s(34, n_splines=200) + \n",
    "    s(35, n_splines=200) + s(36, n_splines=200) + s(37, n_splines=200) + s(38, n_splines=200) + s(39, n_splines=200) + \n",
    "    s(40, n_splines=200) + s(41, n_splines=200) + s(42, n_splines=200) + s(43, n_splines=200) + s(44, n_splines=200) + \n",
    "    s(45, n_splines=200) + s(46, n_splines=200) + s(47, n_splines=200) + s(48, n_splines=200) + s(49, n_splines=200) + \n",
    "    s(50, n_splines=200) + s(51, n_splines=200) + s(52, n_splines=200) + s(53, n_splines=200) + s(54, n_splines=200) + \n",
    "    s(55, n_splines=200) + s(56, n_splines=200) + s(57, n_splines=200) + s(58, n_splines=200))\n",
    "gam.gridsearch(np.array(X_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8a7177",
   "metadata": {},
   "source": [
    "We obtaine a new lambda and see the R2 of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa6578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print('R2 : %.3f' % r2_score(gam.predict(np.array(X_train)), y_train))\n",
    "print('R2 : %.3f' % r2_score(gam.predict(np.array(X_test)), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c06e4a",
   "metadata": {},
   "source": [
    "We pickle the model, to not lose it (it took 2.5 hours to run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97ec2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "score.to_pickle(data_output_path / \"score_v3_GAM.pkl\")\n",
    "data_train.to_pickle(data_output_path / \"data_train_v3_GAM.pkl\")\n",
    "joblib.dump(gbm_random, 'GAM_Q2_copy.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95029bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i, term in enumerate(gam.terms):\n",
    "    if term.isintercept:\n",
    "        continue\n",
    "    plt.plot(gam.partial_dependence(term=i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e164a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(gam.partial_dependence(term=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde8a9e7",
   "metadata": {},
   "source": [
    "After this, we smooth the GAM. We use less basis functions (20 instead of 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa71774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygam import LinearGAM, s\n",
    "\n",
    "## model\n",
    "gam_smooth = LinearGAM(s(0, n_splines=20) + s(1, n_splines=20) + s(2, n_splines=20) + s(3, n_splines=20) + s(4, n_splines=20) + \n",
    "    s(5, n_splines=20) + s(6, n_splines=20) + s(7, n_splines=20) + s(8, n_splines=20) + s(9, n_splines=20) +     \n",
    "    s(10, n_splines=20) + s(11, n_splines=20) + s(12, n_splines=20) + s(13, n_splines=20) + s(14, n_splines=20) + \n",
    "    s(15, n_splines=20) + s(16, n_splines=20) + s(17, n_splines=20) + s(18, n_splines=20) + s(19, n_splines=20) + \n",
    "    s(20, n_splines=20) + s(21, n_splines=20) + s(22, n_splines=20) + s(23, n_splines=20) + s(24, n_splines=20) + \n",
    "    s(25, n_splines=20) + s(26, n_splines=20) + s(27, n_splines=20) + s(28, n_splines=20) + s(29, n_splines=20) + \n",
    "    s(30, n_splines=20) + s(31, n_splines=20) + s(32, n_splines=20) + s(33, n_splines=20) + s(34, n_splines=20) + \n",
    "    s(35, n_splines=20) + s(36, n_splines=20) + s(37, n_splines=20) + s(38, n_splines=20) + s(39, n_splines=20) + \n",
    "    s(40, n_splines=20) + s(41, n_splines=20) + s(42, n_splines=20) + s(43, n_splines=20) + s(44, n_splines=20) + \n",
    "    s(45, n_splines=20) + s(46, n_splines=20) + s(47, n_splines=20) + s(48, n_splines=20) + s(49, n_splines=20) + \n",
    "    s(50, n_splines=20) + s(51, n_splines=20) + s(52, n_splines=20) + s(53, n_splines=20) + s(54, n_splines=20) + \n",
    "    s(55, n_splines=20) + s(56, n_splines=20) + s(57, n_splines=20) + s(58, n_splines=20))\n",
    "gam_smooth.gridsearch(np.array(X_train), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b29098",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(gam_smooth.partial_dependence(term=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b582d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print('R2 : %.3f' % r2_score(gam_smooth.predict(np.array(X_train)), y_train))\n",
    "print('R2 : %.3f' % r2_score(gam_smooth.predict(np.array(X_test)), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82b538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "XX = gam.generate_X_grid(term=3)\n",
    "plt.plot(gam_smooth.partial_dependence(term=3, X=XX, width=.95)[1], c='r', ls='--')\n",
    "plt.plot(gam_smooth.partial_dependence(term=3, X=XX), c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f9cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_preds_gam = gam.predict(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5facb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(data_output_path / \"profit_preds_v3_GAM.pkl\", profit_preds_gam)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "not,title,this,did,do,that,incorrectly_encoded_metadata,things,in,I,way,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
